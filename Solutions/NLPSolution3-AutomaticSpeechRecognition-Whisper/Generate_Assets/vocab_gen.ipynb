{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Inspired from [@ggerganov](https://github.com/ggerganov/whisper.cpp/blob/6f82320b053bb8183a1734e09c940d6bf2a0f4b2/models/convert-pt-to-ggml.py)"
      ],
      "metadata": {
        "id": "qPWqt6hU9AbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Clone whisper repository"
      ],
      "metadata": {
        "id": "J8_qz3GD9S3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzziH8swyL6Z",
        "outputId": "f2d30f80-428e-4f4e-e12c-996047f06ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'whisper'...\n",
            "remote: Enumerating objects: 712, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 712 (delta 1), reused 6 (delta 1), pack-reused 702\u001b[K\n",
            "Receiving objects: 100% (712/712), 12.43 MiB | 29.20 MiB/s, done.\n",
            "Resolving deltas: 100% (419/419), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download tiny openai/whisper model and vocab.json file"
      ],
      "metadata": {
        "id": "bA2_mSFP9Wo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt\n",
        "!wget https://openaipublic.azureedge.net/main/whisper/models/d3dd57d32accea0b295c96e26691aa14d8822fac7d9d27d5dc00b4ca2826dd03/tiny.en.pt\n",
        "!wget https://huggingface.co/openai/whisper-tiny/raw/main/vocab.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x60j4DTT2zs9",
        "outputId": "65574683-5631-4042-bda5-7965167005d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-20 06:10:26--  https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.40, 13.107.213.40, 2620:1ec:bdf::40, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75572083 (72M) [application/octet-stream]\n",
            "Saving to: ‘tiny.pt’\n",
            "\n",
            "tiny.pt             100%[===================>]  72.07M  80.0MB/s    in 0.9s    \n",
            "\n",
            "2023-12-20 06:10:27 (80.0 MB/s) - ‘tiny.pt’ saved [75572083/75572083]\n",
            "\n",
            "--2023-12-20 06:10:27--  https://openaipublic.azureedge.net/main/whisper/models/d3dd57d32accea0b295c96e26691aa14d8822fac7d9d27d5dc00b4ca2826dd03/tiny.en.pt\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.40, 13.107.213.40, 2620:1ec:bdf::40, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75571315 (72M) [application/octet-stream]\n",
            "Saving to: ‘tiny.en.pt’\n",
            "\n",
            "tiny.en.pt          100%[===================>]  72.07M   135MB/s    in 0.5s    \n",
            "\n",
            "2023-12-20 06:10:28 (135 MB/s) - ‘tiny.en.pt’ saved [75571315/75571315]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build tokenzer"
      ],
      "metadata": {
        "id": "yJPzCkef9fX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ref: https://github.com/openai/whisper/blob/8cf36f3508c9acd341a45eb2364239a3d81458b9/whisper/tokenizer.py#L10-L110\n",
        "LANGUAGES = {\n",
        "    \"en\": \"english\",\n",
        "    \"zh\": \"chinese\",\n",
        "    \"de\": \"german\",\n",
        "    \"es\": \"spanish\",\n",
        "    \"ru\": \"russian\",\n",
        "    \"ko\": \"korean\",\n",
        "    \"fr\": \"french\",\n",
        "    \"ja\": \"japanese\",\n",
        "    \"pt\": \"portuguese\",\n",
        "    \"tr\": \"turkish\",\n",
        "    \"pl\": \"polish\",\n",
        "    \"ca\": \"catalan\",\n",
        "    \"nl\": \"dutch\",\n",
        "    \"ar\": \"arabic\",\n",
        "    \"sv\": \"swedish\",\n",
        "    \"it\": \"italian\",\n",
        "    \"id\": \"indonesian\",\n",
        "    \"hi\": \"hindi\",\n",
        "    \"fi\": \"finnish\",\n",
        "    \"vi\": \"vietnamese\",\n",
        "    \"iw\": \"hebrew\",\n",
        "    \"uk\": \"ukrainian\",\n",
        "    \"el\": \"greek\",\n",
        "    \"ms\": \"malay\",\n",
        "    \"cs\": \"czech\",\n",
        "    \"ro\": \"romanian\",\n",
        "    \"da\": \"danish\",\n",
        "    \"hu\": \"hungarian\",\n",
        "    \"ta\": \"tamil\",\n",
        "    \"no\": \"norwegian\",\n",
        "    \"th\": \"thai\",\n",
        "    \"ur\": \"urdu\",\n",
        "    \"hr\": \"croatian\",\n",
        "    \"bg\": \"bulgarian\",\n",
        "    \"lt\": \"lithuanian\",\n",
        "    \"la\": \"latin\",\n",
        "    \"mi\": \"maori\",\n",
        "    \"ml\": \"malayalam\",\n",
        "    \"cy\": \"welsh\",\n",
        "    \"sk\": \"slovak\",\n",
        "    \"te\": \"telugu\",\n",
        "    \"fa\": \"persian\",\n",
        "    \"lv\": \"latvian\",\n",
        "    \"bn\": \"bengali\",\n",
        "    \"sr\": \"serbian\",\n",
        "    \"az\": \"azerbaijani\",\n",
        "    \"sl\": \"slovenian\",\n",
        "    \"kn\": \"kannada\",\n",
        "    \"et\": \"estonian\",\n",
        "    \"mk\": \"macedonian\",\n",
        "    \"br\": \"breton\",\n",
        "    \"eu\": \"basque\",\n",
        "    \"is\": \"icelandic\",\n",
        "    \"hy\": \"armenian\",\n",
        "    \"ne\": \"nepali\",\n",
        "    \"mn\": \"mongolian\",\n",
        "    \"bs\": \"bosnian\",\n",
        "    \"kk\": \"kazakh\",\n",
        "    \"sq\": \"albanian\",\n",
        "    \"sw\": \"swahili\",\n",
        "    \"gl\": \"galician\",\n",
        "    \"mr\": \"marathi\",\n",
        "    \"pa\": \"punjabi\",\n",
        "    \"si\": \"sinhala\",\n",
        "    \"km\": \"khmer\",\n",
        "    \"sn\": \"shona\",\n",
        "    \"yo\": \"yoruba\",\n",
        "    \"so\": \"somali\",\n",
        "    \"af\": \"afrikaans\",\n",
        "    \"oc\": \"occitan\",\n",
        "    \"ka\": \"georgian\",\n",
        "    \"be\": \"belarusian\",\n",
        "    \"tg\": \"tajik\",\n",
        "    \"sd\": \"sindhi\",\n",
        "    \"gu\": \"gujarati\",\n",
        "    \"am\": \"amharic\",\n",
        "    \"yi\": \"yiddish\",\n",
        "    \"lo\": \"lao\",\n",
        "    \"uz\": \"uzbek\",\n",
        "    \"fo\": \"faroese\",\n",
        "    \"ht\": \"haitian creole\",\n",
        "    \"ps\": \"pashto\",\n",
        "    \"tk\": \"turkmen\",\n",
        "    \"nn\": \"nynorsk\",\n",
        "    \"mt\": \"maltese\",\n",
        "    \"sa\": \"sanskrit\",\n",
        "    \"lb\": \"luxembourgish\",\n",
        "    \"my\": \"myanmar\",\n",
        "    \"bo\": \"tibetan\",\n",
        "    \"tl\": \"tagalog\",\n",
        "    \"mg\": \"malagasy\",\n",
        "    \"as\": \"assamese\",\n",
        "    \"tt\": \"tatar\",\n",
        "    \"haw\": \"hawaiian\",\n",
        "    \"ln\": \"lingala\",\n",
        "    \"ha\": \"hausa\",\n",
        "    \"ba\": \"bashkir\",\n",
        "    \"jw\": \"javanese\",\n",
        "    \"su\": \"sundanese\",\n",
        "}"
      ],
      "metadata": {
        "id": "LJU0X5QJ5TWa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ref: https://github.com/openai/gpt-2/blob/master/src/encoder.py\n",
        "def bytes_to_unicode():\n",
        "    \"\"\"\n",
        "    Returns list of utf-8 byte and a corresponding list of unicode strings.\n",
        "    The reversible bpe codes work on unicode strings.\n",
        "    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n",
        "    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n",
        "    This is a signficant percentage of your normal, say, 32K bpe vocab.\n",
        "    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n",
        "    And avoids mapping to whitespace/control characters the bpe code barfs on.\n",
        "    \"\"\"\n",
        "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"¡\"), ord(\"¬\")+1))+list(range(ord(\"®\"), ord(\"ÿ\")+1))\n",
        "    cs = bs[:]\n",
        "    n = 0\n",
        "    for b in range(2**8):\n",
        "        if b not in bs:\n",
        "            bs.append(b)\n",
        "            cs.append(2**8+n)\n",
        "            n += 1\n",
        "    cs = [chr(n) for n in cs]\n",
        "    return dict(zip(bs, cs))"
      ],
      "metadata": {
        "id": "ubnuRn2475bg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate filters and vocab binary"
      ],
      "metadata": {
        "id": "rqPLYlya9lE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import sys\n",
        "import struct\n",
        "import json\n",
        "import code\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "fname_inp = \"/content/tiny.en.pt\"\n",
        "# try to load PyTorch binary data\n",
        "try:\n",
        "    model_bytes = open(fname_inp, \"rb\").read()\n",
        "    with io.BytesIO(model_bytes) as fp:\n",
        "        checkpoint = torch.load(fp, map_location=\"cpu\")\n",
        "except:\n",
        "    print(\"Error: failed to load PyTorch model file: %s\" % fname_inp)\n",
        "    sys.exit(1)\n",
        "\n",
        "whisperparams = checkpoint[\"dims\"]\n",
        "print(\"whisperparams:\", whisperparams)\n",
        "list_vars = checkpoint[\"model_state_dict\"]\n",
        "#print(list_vars['encoder.positional_embedding'])\n",
        "#print(list_vars['encoder.conv1.weight'])\n",
        "#print(list_vars['encoder.conv1.weight'].shape)\n",
        "\n",
        "# load mel filters\n",
        "n_mels = whisperparams[\"n_mels\"]\n",
        "with np.load(os.path.join(\"/content/whisper/whisper/assets\", \"mel_filters.npz\")) as f:\n",
        "    filters = torch.from_numpy(f[f\"mel_{n_mels}\"])\n",
        "    #print (filters)\n",
        "\n",
        "#print(tokenizer)\n",
        "#print(tokenizer.name_or_path)\n",
        "#print(len(tokenizer.additional_special_tokens))\n",
        "\n",
        "# output in the same directory as the model\n",
        "fname_out = \"./filters_vocab_gen.bin\"\n",
        "with open(\"/content/vocab.json\", \"r\", encoding=\"utf8\") as f:\n",
        "    tokens = json.load(f)\n",
        "fout = open(fname_out, \"wb\")\n",
        "fout.write(struct.pack(\"i\", 0x5553454e)) # magic: USEN in hex\n",
        "#fout.write(struct.pack(\"i\", whisperparams[\"n_vocab\"]))\n",
        "#print(\"n_vocab:\",whisperparams[\"n_vocab\"])\n",
        "#fout.write(struct.pack(\"i\", whisperparams[\"n_mels\"]))\n",
        "#print(\"n_mels:\",n_mels)\n",
        "# write mel filters\n",
        "fout.write(struct.pack(\"i\", filters.shape[0]))\n",
        "print(\"filters.shape[0]:\",filters.shape[0])\n",
        "fout.write(struct.pack(\"i\", filters.shape[1]))\n",
        "print(\"filters.shape[0]:\",filters.shape[1])\n",
        "for i in range(filters.shape[0]):\n",
        "    for j in range(filters.shape[1]):\n",
        "        fout.write(struct.pack(\"f\", filters[i][j]))\n",
        "byte_encoder = bytes_to_unicode()\n",
        "byte_decoder = {v:k for k, v in byte_encoder.items()}\n",
        "\n",
        "fout.write(struct.pack(\"i\", len(tokens)))\n",
        "print(\"len(tokens):\",len(tokens))\n",
        "for key in tokens:\n",
        "    text = bytearray([byte_decoder[c] for c in key])\n",
        "    fout.write(struct.pack(\"i\", len(text)))\n",
        "    fout.write(text)\n",
        "fout.close()\n",
        "\n",
        "print(\"Done. Output file: \" + fname_out)\n",
        "print(\"\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6xl0Bn30J08",
        "outputId": "5cc66835-75a3-4058-8c6d-13e0c5477ee1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whisperparams: {'n_mels': 80, 'n_vocab': 51864, 'n_audio_ctx': 1500, 'n_audio_state': 384, 'n_audio_head': 6, 'n_audio_layer': 4, 'n_text_ctx': 448, 'n_text_state': 384, 'n_text_head': 6, 'n_text_layer': 4}\n",
            "filters.shape[0]: 80\n",
            "filters.shape[0]: 201\n",
            "len(tokens): 50258\n",
            "Done. Output file: ./filters_vocab_gen.bin\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z0fUzw8M8838"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1I78JK7T2ePB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}