{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85201f90-f251-4c26-a21a-977a68bfc723",
   "metadata": {},
   "source": [
    "### Loading the Necessary Github Repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e9a30b-75aa-4800-8139-6c3ac6624c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-xcvwhboy\n",
      "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-xcvwhboy\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numba\n",
      "  Downloading numba-0.58.1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 24.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting more-itertools\n",
      "  Downloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./temp_env/lib/python3.8/site-packages (from openai-whisper==20231117) (1.23.5)\n",
      "Requirement already satisfied: tqdm in ./temp_env/lib/python3.8/site-packages (from openai-whisper==20231117) (4.66.1)\n",
      "Collecting triton<3,>=2.0.0\n",
      "  Downloading triton-2.1.0-0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 89.2 MB 11 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting tiktoken\n",
      "  Downloading tiktoken-0.5.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 91.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.1.1-cp38-cp38-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[K     |███████████████                 | 312.2 MB 111.9 MB/s eta 0:00:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |███████████████████████████████ | 647.8 MB 96.8 MB/s eta 0:00:011     |█████████████████████████████▌  | 618.6 MB 96.8 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 670.2 MB 13 kB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.9\" in ./temp_env/lib/python3.8/site-packages (from numba->openai-whisper==20231117) (7.0.0)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Downloading llvmlite-0.41.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 43.6 MB 103.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./temp_env/lib/python3.8/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Collecting regex>=2022.1.18\n",
      "  Downloading regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[K     |████████████████████████████████| 776 kB 132.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 6.6 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 165.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[K     |█████████████▉                  | 316.8 MB 106.9 MB/s eta 0:00:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████    | 640.3 MB 111.6 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 731.7 MB 9.0 kB/s \n",
      "\u001b[?25hRequirement already satisfied: jinja2 in ./temp_env/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 130.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 124.2 MB 16 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 209.8 MB 2.0 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 56.5 MB 81 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 196.0 MB 30 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2023.12.0-py3-none-any.whl (168 kB)\n",
      "\u001b[K     |████████████████████████████████| 168 kB 114.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 94.8 MB/s eta 0:00:01    |███▏                            | 1.4 MB 94.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./temp_env/lib/python3.8/site-packages (from torch->openai-whisper==20231117) (4.6.2)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[K     |██████████████████████▉         | 292.4 MB 112.1 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 410.6 MB 126.1 MB/s \n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 121.6 MB 111.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 164.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 115.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in ./temp_env/lib/python3.8/site-packages (from importlib-metadata; python_version < \"3.9\"->numba->openai-whisper==20231117) (3.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./temp_env/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./temp_env/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./temp_env/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./temp_env/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./temp_env/lib/python3.8/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.5 MB 83.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 147.9 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801356 sha256=1ace2bd4f7a7795f42c3b1cb977e6b42228106e329b6d455b526ce39b04f1352\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3dxms940/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: llvmlite, numba, more-itertools, filelock, triton, regex, tiktoken, nvidia-nvtx-cu12, networkx, nvidia-cublas-cu12, nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cusolver-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, fsspec, nvidia-cuda-cupti-cu12, nvidia-cufft-cu12, mpmath, sympy, nvidia-cuda-nvrtc-cu12, torch, openai-whisper\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 28] No space left on device\n",
      "\u001b[0m\n",
      "Collecting onnx\n",
      "  Downloading onnx-1.15.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.7 MB 24.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./temp_env/lib/python3.8/site-packages (from onnx) (1.23.5)\n",
      "Collecting protobuf>=3.20.2\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 122.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: protobuf, onnx\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "Successfully installed onnx-1.15.0 protobuf-4.25.1\n",
      "Collecting onnx_tf\n",
      "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
      "\u001b[K     |████████████████████████████████| 226 kB 26.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: onnx>=1.10.2 in ./temp_env/lib/python3.8/site-packages (from onnx_tf) (1.15.0)\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
      "\u001b[K     |████████████████████████████████| 612 kB 105.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in ./temp_env/lib/python3.8/site-packages (from onnx_tf) (6.0.1)\n",
      "Requirement already satisfied: numpy in ./temp_env/lib/python3.8/site-packages (from onnx>=1.10.2->onnx_tf) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./temp_env/lib/python3.8/site-packages (from onnx>=1.10.2->onnx_tf) (4.25.1)\n",
      "Collecting typeguard<3.0.0,>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: packaging in ./temp_env/lib/python3.8/site-packages (from tensorflow-addons->onnx_tf) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./temp_env/lib/python3.8/site-packages (from packaging->tensorflow-addons->onnx_tf) (3.1.1)\n",
      "Installing collected packages: typeguard, tensorflow-addons, onnx-tf\n",
      "Successfully installed onnx-tf-1.10.0 tensorflow-addons-0.21.0 typeguard-2.13.3\n",
      "Cloning into 'openai-whisper'...\n",
      "remote: Enumerating objects: 935, done.\u001b[K\n",
      "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
      "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
      "remote: Total 935 (delta 124), reused 119 (delta 118), pack-reused 796\u001b[K\n",
      "Receiving objects: 100% (935/935), 255.38 MiB | 20.10 MiB/s, done.\n",
      "Resolving deltas: 100% (362/362), done.\n",
      "Updating files: 100% (414/414), done.\n",
      "Filtering content: 100% (10/10), 1.50 GiB | 45.53 MiB/s, done.\n",
      "Encountered 5 file(s) that should have been pointers, but weren't:\n",
      "\tmodels/whisper-decoder_language.tflite\n",
      "\tmodels/whisper-decoder_main.tflite\n",
      "\tmodels/whisper-encoder-int8.tflite\n",
      "\tmodels/whisper-encoder.tflite\n",
      "\tmodels/whisper-int8.tflite\n",
      "Cloning into 'whisper'...\n",
      "remote: Enumerating objects: 702, done.\u001b[K\n",
      "remote: Total 702 (delta 0), reused 0 (delta 0), pack-reused 702\u001b[K\n",
      "Receiving objects: 100% (702/702), 12.41 MiB | 7.53 MiB/s, done.\n",
      "Resolving deltas: 100% (418/418), done.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git \n",
    "!pip install onnx\n",
    "!pip install onnx_tf\n",
    "!git clone https://github.com/usefulsensors/openai-whisper.git\n",
    "!git clone https://github.com/openai/whisper.git "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2665aca-9241-4283-a96f-e3beb31572ce",
   "metadata": {},
   "source": [
    "### Installing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6bece-dce6-416b-bc7a-8cda0a72e81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[K     |████████████████                | 311.4 MB 120.5 MB/s eta 0:00:03   |███▏                            | 61.8 MB 24.3 MB/s eta 0:00:23     |███▉                            | 73.5 MB 24.3 MB/s eta 0:00:23"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |█████████████████████████████▍  | 568.9 MB 111.6 MB/s eta 0:00:01     |███████████████████████▋        | 457.6 MB 106.7 MB/s eta 0:00:02"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers==4.29.2 \n",
    "!pip3 install safetensors==0.3.0\n",
    "!pip3 install pyyaml==5.3\n",
    "!pip3 install numpy==1.22.2\n",
    "!pip3 install torchvision==0.15.2\n",
    "!pip3 install packaging==21.3\n",
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d17617-b1fa-4693-8c3d-d78250206eab",
   "metadata": {},
   "source": [
    "### Getting the Encoder ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a3750cd1-4bbb-493d-93da-5c27318c9457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages/whisper/model.py:166: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert x.shape[1:] == self.positional_embedding.shape, \"incorrect audio shape\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import onnx\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "import tqdm\n",
    "from onnx_tf.backend import prepare\n",
    "from whisper.audio import load_audio, log_mel_spectrogram,pad_or_trim,N_FRAMES, SAMPLE_RATE\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "#load openai->whisper(pytorch)->tiny model\n",
    "tiny_model = whisper.load_model(\"tiny\")\n",
    "\n",
    "#Export to onnx format\n",
    "torch.onnx.export(tiny_model.encoder,torch.randn(1,80,3000).to(device), \"./whisper_encoder.onnx\",opset_version=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b59f9-0cae-42ac-bc48-2d58acfc0fd5",
   "metadata": {},
   "source": [
    "### IDEA\n",
    "**Basic Idea will be**\n",
    "- Encoder will run as dlc\n",
    "- Decoder will run as ONNX Model\n",
    "- Now whatever i'll get from decoder that will be added with previous decoder then multiplied with the encoder result\n",
    "\n",
    "![modelArchitecture](image-assets/whisper_model_Architecture.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085ee3a-ab4c-4930-9a4e-e5a43ac18358",
   "metadata": {},
   "source": [
    "#### Normal Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7114916-9d31-417a-95ae-cdd4abff9747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.8.1\n",
      "  Downloading torch-1.8.1-cp38-cp38-manylinux1_x86_64.whl (804.1 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.2/804.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:04:03\u001b[0m^C\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.3/804.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:04:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "Requirement already satisfied: onnxruntime in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (1.16.3)\n",
      "Requirement already satisfied: coloredlogs in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from onnxruntime) (23.5.26)\n",
      "Collecting numpy>=1.21.6 (from onnxruntime)\n",
      "  Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: packaging in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from onnxruntime) (21.3)\n",
      "Requirement already satisfied: protobuf in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from onnxruntime) (3.19.6)\n",
      "Requirement already satisfied: sympy in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from packaging->onnxruntime) (3.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Using cached numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.0\n",
      "    Uninstalling numpy-1.21.0:\n",
      "      Successfully uninstalled numpy-1.21.0\n",
      "Successfully installed numpy-1.24.4\n",
      "Requirement already satisfied: tensorflow==2.10.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (2.10.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (0.3.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (1.59.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (2.10.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (1.24.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (3.3.0)\n",
      "Requirement already satisfied: packaging in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (0.34.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorflow==2.10.1) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.10.1) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.2.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from packaging->tensorflow==2.10.1) (3.1.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.17.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.2.2)\n",
      "Requirement already satisfied: tflite==2.3.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: flatbuffers in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tflite==2.3.0) (23.5.26)\n",
      "Requirement already satisfied: numpy in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from tflite==2.3.0) (1.24.4)\n",
      "Requirement already satisfied: soundfile in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: librosa in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (0.10.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (0.58.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (4.5.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
      "Requirement already satisfied: importlib-metadata in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from numba>=0.51.0->librosa) (6.8.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from pooch>=1.0->librosa) (4.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from pooch>=1.0->librosa) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from packaging>=20.0->pooch>=1.0->librosa) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n",
      "Requirement already satisfied: zipp>=0.5 in /local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages (from importlib-metadata->numba>=0.51.0->librosa) (3.17.0)\n",
      "Collecting numpy==1.22\n",
      "  Downloading numpy-1.22.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "librosa 0.10.1 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.22.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.8.1 \n",
    "!pip3 install onnxruntime\n",
    "!pip3 install tensorflow==2.10.1\n",
    "!pip3 install tflite==2.3.0\n",
    "!pip3 install soundfile\n",
    "!pip3 install librosa\n",
    "!pip3 install numpy==1.22\n",
    "#!pip3 install numpy==1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8e4cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages/transformers/modeling_utils.py:433: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n",
      "2023-12-20 10:53:08.745471: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 10:53:08.826307: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-20 10:53:08.843568: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-20 10:53:09.185679: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/qaisw-v2.15.1.230926150623_62883/lib/x86_64-linux-clang\n",
      "2023-12-20 10:53:09.185736: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/qaisw-v2.15.1.230926150623_62883/lib/x86_64-linux-clang\n",
      "2023-12-20 10:53:09.185740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/mnt/workspace/sahinhos/sahin_env_3/lib/python3.8/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
    "\n",
    "\n",
    "# load dummy dataset and read audio files\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "sample = ds[0][\"audio\"]\n",
    "input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\") \n",
    "# generate token ids\n",
    "predicted_ids = model.generate(**input_features,decoder_input_ids=torch.tensor([[50258, 50259, 50359, 50363]]))\n",
    "# decode token ids to text\n",
    "\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a9e4b-a1ae-4a34-8417-dba3c60d292a",
   "metadata": {},
   "source": [
    "#### Getting The Special Token Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86bc79c6-98c6-462f-86fe-295fff052fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{50257: '<|endoftext|>', 50258: '<|startoftranscript|>', 50259: '<|en|>', 50260: '<|zh|>', 50261: '<|de|>', 50262: '<|es|>', 50263: '<|ru|>', 50264: '<|ko|>', 50265: '<|fr|>', 50266: '<|ja|>', 50267: '<|pt|>', 50268: '<|tr|>', 50269: '<|pl|>', 50270: '<|ca|>', 50271: '<|nl|>', 50272: '<|ar|>', 50273: '<|sv|>', 50274: '<|it|>', 50275: '<|id|>', 50276: '<|hi|>', 50277: '<|fi|>', 50278: '<|vi|>', 50279: '<|he|>', 50280: '<|uk|>', 50281: '<|el|>', 50282: '<|ms|>', 50283: '<|cs|>', 50284: '<|ro|>', 50285: '<|da|>', 50286: '<|hu|>', 50287: '<|ta|>', 50288: '<|no|>', 50289: '<|th|>', 50290: '<|ur|>', 50291: '<|hr|>', 50292: '<|bg|>', 50293: '<|lt|>', 50294: '<|la|>', 50295: '<|mi|>', 50296: '<|ml|>', 50297: '<|cy|>', 50298: '<|sk|>', 50299: '<|te|>', 50300: '<|fa|>', 50301: '<|lv|>', 50302: '<|bn|>', 50303: '<|sr|>', 50304: '<|az|>', 50305: '<|sl|>', 50306: '<|kn|>', 50307: '<|et|>', 50308: '<|mk|>', 50309: '<|br|>', 50310: '<|eu|>', 50311: '<|is|>', 50312: '<|hy|>', 50313: '<|ne|>', 50314: '<|mn|>', 50315: '<|bs|>', 50316: '<|kk|>', 50317: '<|sq|>', 50318: '<|sw|>', 50319: '<|gl|>', 50320: '<|mr|>', 50321: '<|pa|>', 50322: '<|si|>', 50323: '<|km|>', 50324: '<|sn|>', 50325: '<|yo|>', 50326: '<|so|>', 50327: '<|af|>', 50328: '<|oc|>', 50329: '<|ka|>', 50330: '<|be|>', 50331: '<|tg|>', 50332: '<|sd|>', 50333: '<|gu|>', 50334: '<|am|>', 50335: '<|yi|>', 50336: '<|lo|>', 50337: '<|uz|>', 50338: '<|fo|>', 50339: '<|ht|>', 50340: '<|ps|>', 50341: '<|tk|>', 50342: '<|nn|>', 50343: '<|mt|>', 50344: '<|sa|>', 50345: '<|lb|>', 50346: '<|my|>', 50347: '<|bo|>', 50348: '<|tl|>', 50349: '<|mg|>', 50350: '<|as|>', 50351: '<|tt|>', 50352: '<|haw|>', 50353: '<|ln|>', 50354: '<|ha|>', 50355: '<|ba|>', 50356: '<|jw|>', 50357: '<|su|>', 50358: '<|translate|>', 50359: '<|transcribe|>', 50360: '<|startoflm|>', 50361: '<|startofprev|>', 50362: '<|nocaptions|>', 50363: '<|notimestamps|>'}\n"
     ]
    }
   ],
   "source": [
    "special_tokens=['<|endoftext|>', '<|startoftranscript|>', '<|en|>', '<|zh|>', '<|de|>', '<|es|>', '<|ru|>', '<|ko|>', '<|fr|>', '<|ja|>', '<|pt|>', '<|tr|>', '<|pl|>', '<|ca|>', '<|nl|>', '<|ar|>', '<|sv|>', '<|it|>', '<|id|>', '<|hi|>', '<|fi|>', '<|vi|>', '<|he|>', '<|uk|>', '<|el|>', '<|ms|>', '<|cs|>', '<|ro|>', '<|da|>', '<|hu|>', '<|ta|>', '<|no|>', '<|th|>', '<|ur|>', '<|hr|>', '<|bg|>', '<|lt|>', '<|la|>', '<|mi|>', '<|ml|>', '<|cy|>', '<|sk|>', '<|te|>', '<|fa|>', '<|lv|>', '<|bn|>', '<|sr|>', '<|az|>', '<|sl|>', '<|kn|>', '<|et|>', '<|mk|>', '<|br|>', '<|eu|>', '<|is|>', '<|hy|>', '<|ne|>', '<|mn|>', '<|bs|>', '<|kk|>', '<|sq|>', '<|sw|>', '<|gl|>', '<|mr|>', '<|pa|>', '<|si|>', '<|km|>', '<|sn|>', '<|yo|>', '<|so|>', '<|af|>', '<|oc|>', '<|ka|>', '<|be|>', '<|tg|>', '<|sd|>', '<|gu|>', '<|am|>', '<|yi|>', '<|lo|>', '<|uz|>', '<|fo|>', '<|ht|>', '<|ps|>', '<|tk|>', '<|nn|>', '<|mt|>', '<|sa|>', '<|lb|>', '<|my|>', '<|bo|>', '<|tl|>', '<|mg|>', '<|as|>', '<|tt|>', '<|haw|>', '<|ln|>', '<|ha|>', '<|ba|>', '<|jw|>', '<|su|>', '<|translate|>', '<|transcribe|>', '<|startoflm|>', '<|startofprev|>', '<|nocaptions|>', '<|notimestamps|>']\n",
    "\n",
    "dict={50257+i:special_tokens[i] for i in range(0,len(special_tokens))}\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86684ee2-5d44-4f87-8be8-dce92a8c3028",
   "metadata": {},
   "source": [
    "#### Getting Different Token ids for Different Tasks\n",
    "- Right Now I've used For english language Transcribtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf65713-2fa5-4667-aa6e-218662994ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 50259), (2, 50359), (3, 50363)]\n",
      "[50258, 50259, 50359, 50363]\n",
      "[[50258 50259 50359 50363]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoConfig, AutoProcessor\n",
    "\n",
    "\n",
    "model = \"openai/whisper-tiny\"\n",
    "config = AutoConfig.from_pretrained(model)\n",
    "processor = AutoProcessor.from_pretrained(model)\n",
    "\n",
    "# English transcription\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"en\", task=\"transcribe\")\n",
    "print(forced_decoder_ids)\n",
    "# forced_decoder_ids is of the format [(1, 50259), (2, 50359), (3, 50363)] and needs to be\n",
    "# of the format [50258, 50259, 50359, 50363] where 50258 is the start token id\n",
    "forced_decoder_ids = [config.decoder_start_token_id] + list(map(lambda token: token[1], forced_decoder_ids))\n",
    "print(forced_decoder_ids)\n",
    "# If you don't want to provide specific decoder input ids or you want\n",
    "# Whisper to predict the output language and task, you can set\n",
    "# forced_decoder_ids = [config.decoder_start_token_id]\n",
    "# [50258]\n",
    "\n",
    "# decoder input ids\n",
    "decoder_input_ids = np.array([forced_decoder_ids], dtype=np.int32)\n",
    "print(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b993f9b2-6a6b-4915-a9e9-1ca3eeef0142",
   "metadata": {},
   "source": [
    "## Getting the ONNX Model\n",
    "- Some error during exporting the onnx model\n",
    "- Now i'll mainly focus on Whisper Notebook\n",
    "- With this it'll not work, i've used other method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360148c8-9423-42a2-b5cb-c5660b71731f",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093bc9e4-e1ec-4ced-8da5-8d522c1165f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id'],\n",
      "    num_rows: 73\n",
      "})\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n",
      "(1, 80, 3000)\n",
      "(1, 3000, 80)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "# loading the processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
    "!rm -rf input_features\n",
    "os.makedirs('input_features',exist_ok=True)\n",
    "\n",
    "# load dummy dataset and read audio files\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "print(ds)\n",
    "for i in range(25):\n",
    "    sample = ds[i][\"audio\"]\n",
    "    input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"np\") \n",
    "    \n",
    "    inp_val=input_features.input_features.astype(np.float32)\n",
    "    #Need to transpose the input\n",
    "    print(inp_val.shape)\n",
    "    updated_inp_val=inp_val.transpose(0,2,1)\n",
    "    print(updated_inp_val.shape)\n",
    "    with open(\"input_features/inp_val_\"+str(i)+\".raw\", 'wb') as f:\n",
    "        updated_inp_val.tofile(f)\n",
    "\n",
    "\n",
    "#Creating list.txt\n",
    "with open(\"list.txt\",'w') as f:\n",
    "    for i in range(25):\n",
    "        f.write(\"x.1:=input_features/inp_val_\"+str(i)+\".raw\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54418e2f-49e7-4b15-ac19-0eb614ce388e",
   "metadata": {},
   "source": [
    "##### Running the Decoder Model\n",
    "- Now i'll take the last_hidden_state of the encoder model\n",
    "- Then i'll take the initial decoder_input_ids then one by one i'll add\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0622ad7-a456-4dd7-a805-3bcc90f12e17",
   "metadata": {},
   "source": [
    "##### Tflite Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e4a16c4-7890-402b-ba5f-34e5696c0043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai-whisper/models/whisper-decoder-tiny.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
      "2023-12-20 10:53:54.516278: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 10:53:54.517352: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /local/mnt/workspace/snpe/qaisw-v2.15.1.230926150623_62883/lib/x86_64-linux-clang\n",
      "2023-12-20 10:53:54.517362: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-12-20 10:53:54.517372: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hyd-lablnx950): /proc/driver/nvidia/version does not exist\n",
      "INFO: TfLiteFlexDelegate delegate: 28 nodes delegated out of 781 nodes with 12 partitions.\n",
      "\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import (\n",
    "        AutoTokenizer\n",
    "    )\n",
    "model_id = \"openai/whisper-tiny\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "tflite_model_path='openai-whisper/models/whisper-decoder-tiny.tflite'\n",
    "#tflite_model_path='/content/whisper-decoder_main-int8.tflite'\n",
    "print(tflite_model_path)\n",
    "\n",
    "# Load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "\n",
    "\n",
    "def decoder_block_tflite(encoder_hidden_states):\n",
    "    \n",
    "    decoder_input_ids = torch.tensor([50258, 50259, 50359, 50363])\n",
    "    decoder_input_ids = tf.expand_dims(decoder_input_ids, 0)\n",
    "    \n",
    "    input_tensor_1 = interpreter.get_input_details()[0]['index']\n",
    "    \n",
    "    interpreter.set_tensor(input_tensor_1, encoder_hidden_states)\n",
    "    \n",
    "    input_tensor_2 = interpreter.get_input_details()[1]['index']\n",
    "    interpreter.resize_tensor_input(input_tensor_2, decoder_input_ids.shape)\n",
    "    # Allocate memory for input and output tensors\n",
    "    interpreter.allocate_tensors()\n",
    "    interpreter.set_tensor(input_tensor_2, decoder_input_ids)\n",
    "    output_tensor = interpreter.get_output_details()[0]['index']\n",
    "    start_tokens = [50258, 50259, 50359, 50363] \n",
    "    tokens = start_tokens\n",
    "    while(True):\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_tensor) \n",
    "        # print(output_data.shape)\n",
    "        # print(output_data)\n",
    "        cleaned = np.argmax(output_data, axis=-1)\n",
    "        # print(\"cleaned\",cleaned)\n",
    "        last_token = cleaned[0,-1]\n",
    "        # print(\"Last Token\",last_token)\n",
    "        tokens.append(last_token)\n",
    "        # print(\"Updated tokens:\",tokens)\n",
    "        new_value = tf.constant([last_token], dtype=tf.int64)\n",
    "        new_value = tf.reshape(new_value, (1,1))\n",
    "        decoder_input_ids = tf.concat([decoder_input_ids, new_value], axis=1)\n",
    "        input_tensor_2 = interpreter.get_input_details()[1]['index']\n",
    "        interpreter.resize_tensor_input(input_tensor_2, decoder_input_ids.shape)\n",
    "        # Allocate memory for input and output tensors\n",
    "        interpreter.allocate_tensors()\n",
    "        interpreter.set_tensor(input_tensor_2, decoder_input_ids)\n",
    "        if last_token == 50257:\n",
    "          break\n",
    "    \n",
    "    \n",
    "    return tokenizer.batch_decode(np.expand_dims(tokens, axis=0), skip_special_tokens=True)[0]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923d62d-28fe-43d1-b86b-158de52e7940",
   "metadata": {},
   "source": [
    "#### Getting the DLC Model\n",
    "- The above ONNX model is running successfully\n",
    "- Now Converting to DLC and checking how it's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9cbc4e7-3fdf-4d6b-be09-fed18d45bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['SNPE_ROOT']=\"../../../../snpe/2.16.0.231029\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14935c-b4ae-41cf-90d1-e6efceebeb2e",
   "metadata": {},
   "source": [
    "#### Getting the Fp32 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "283f4b82-166e-464f-953c-65c6cc75f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] AISW SDK environment set\n",
      "[INFO] SNPE_ROOT: /local/mnt/workspace/snpe/2.16.0.231029\n",
      "\u001b[1;31mWARNING: The argument `input_shapes` is deprecated. Please use \u001b[0m\n",
      "\u001b[1;31m`overwrite_input_shapes` and/or `test_input_shapes` instead. An error will be \u001b[0m\n",
      "\u001b[1;31mraised in the future.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 14:33:11,345 - 240 - WARNING - Model simplification failed with unexpected exception\n",
      "2023-12-04 14:33:11,354 - 240 - WARNING - Try simplification again by skipping optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mWARNING: The argument `input_shapes` is deprecated. Please use \u001b[0m\n",
      "\u001b[1;31m`overwrite_input_shapes` and/or `test_input_shapes` instead. An error will be \u001b[0m\n",
      "\u001b[1;31mraised in the future.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 14:33:11,472 - 240 - WARNING - Model simplification failed with unexpected exception\n",
      "2023-12-04 14:33:11,480 - 240 - WARNING - Resume normal conversion with unsimplified model\n",
      "2023-12-04 14:33:11,525 - 235 - INFO - Successfully run shape inference in child process\n",
      "2023-12-04 14:33:11,641 - 235 - INFO - Successfully receive the inferred model in main process\n",
      "2023-12-04 14:33:11,657 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,657 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.0/attn_ln/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,660 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.0/attn_ln/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,666 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.0/attn/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,667 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.0/attn/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,670 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.0/mlp_ln/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,672 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.0/mlp_ln/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,677 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.1/attn_ln/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,680 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.1/attn_ln/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,686 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.1/attn/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,686 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.1/attn/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,689 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.1/mlp_ln/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,692 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.1/mlp_ln/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,697 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.2/attn_ln/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,699 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.2/attn_ln/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,705 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.2/attn/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,706 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.2/attn/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,709 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.2/mlp_ln/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,711 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.2/mlp_ln/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,716 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.3/attn_ln/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,719 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.3/attn_ln/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,725 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.3/attn/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,726 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.3/attn/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,729 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.3/mlp_ln/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,731 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /blocks.3/mlp_ln/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,743 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /ln_post/Cast will be interpreted at conversion time\n",
      "2023-12-04 14:33:11,745 - 240 - WARNING - WARNING_CAST_TYPE: Only numerical type cast is supported. The op: /ln_post/Cast_1 will be interpreted at conversion time\n",
      "2023-12-04 14:33:12,284 - 235 - INFO - INFO_INITIALIZATION_SUCCESS: \n",
      "2023-12-04 14:33:12,368 - 235 - INFO - INFO_CONVERSION_SUCCESS: Conversion completed successfully\n",
      "2023-12-04 14:33:12,408 - 235 - INFO - INFO_WRITE_SUCCESS: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Model HTML file saved at /local/mnt/workspace/sahinhos/sahinworkspace/aimet-model-zoo/Whisper_tiny/whisper_tiny_encoder_fp32.html\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "\n",
    "snpe-onnx-to-dlc -i whisper_encoder.onnx -d x.1 1,80,3000 -o whisper_tiny_encoder_fp32.dlc\n",
    "snpe-dlc-info -i whisper_tiny_encoder_fp32.dlc > whisper_tiny_encoder_fp32.txt\n",
    "snpe-dlc-viewer -i whisper_tiny_encoder_fp32.dlc -s whisper_tiny_encoder_fp32.html "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd4f7c0-ad27-4a02-b660-3f9d0d4cd11a",
   "metadata": {},
   "source": [
    "#### Creating w8a8 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52ad99d7-f80b-4f0b-b0c8-42b36f32a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] AISW SDK environment set\n",
      "[INFO] SNPE_ROOT: /local/mnt/workspace/snpe/2.16.0.231029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] InitializeStderr: DebugLog initialized.\n",
      "[INFO] Processed command-line arguments\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runAlgorithms: Running CLE quantization algorithms\n",
      "HighBiasAbsorption: Running high bias absorption algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Quantized parameters\n",
      "[INFO] Generated activations\n",
      "[INFO] Saved quantized dlc to: whisper_tiny_encoder_w8a16.dlc\n",
      "[INFO] DebugLog shutting down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.0ms [  INFO ] Inferences will run in sync mode\n",
      "     0.1ms [  INFO ] Initializing logging in the backend. Callback: [0xcf3a80], Log Level: [3]\n",
      "     0.1ms [  INFO ] No BackendExtensions lib provided;initializing NetRunBackend Interface\n",
      "     0.1ms [WARNING] Unable to find a device with NetRunDeviceKeyDefault in Library NetRunBackendLibKeyDefault\n",
      "     0.1ms [  INFO ] Entering QuantizeRuntimeApp flow\n",
      "   835.0ms [  INFO ] cleaning up resources for input tensors\n",
      "   835.0ms [  INFO ] cleaning up resources for output tensors\n",
      "  1566.2ms [  INFO ] cleaning up resources for input tensors\n",
      "  1566.2ms [  INFO ] cleaning up resources for output tensors\n",
      "  2299.3ms [  INFO ] cleaning up resources for input tensors\n",
      "  2299.3ms [  INFO ] cleaning up resources for output tensors\n",
      "  3039.2ms [  INFO ] cleaning up resources for input tensors\n",
      "  3039.2ms [  INFO ] cleaning up resources for output tensors\n",
      "  3774.3ms [  INFO ] cleaning up resources for input tensors\n",
      "  3774.3ms [  INFO ] cleaning up resources for output tensors\n",
      "  4510.9ms [  INFO ] cleaning up resources for input tensors\n",
      "  4510.9ms [  INFO ] cleaning up resources for output tensors\n",
      "  5240.2ms [  INFO ] cleaning up resources for input tensors\n",
      "  5240.2ms [  INFO ] cleaning up resources for output tensors\n",
      "  5980.9ms [  INFO ] cleaning up resources for input tensors\n",
      "  5980.9ms [  INFO ] cleaning up resources for output tensors\n",
      "  6717.3ms [  INFO ] cleaning up resources for input tensors\n",
      "  6717.3ms [  INFO ] cleaning up resources for output tensors\n",
      "  7441.1ms [  INFO ] cleaning up resources for input tensors\n",
      "  7441.1ms [  INFO ] cleaning up resources for output tensors\n",
      "  8183.4ms [  INFO ] cleaning up resources for input tensors\n",
      "  8183.4ms [  INFO ] cleaning up resources for output tensors\n",
      "  8932.2ms [  INFO ] cleaning up resources for input tensors\n",
      "  8932.2ms [  INFO ] cleaning up resources for output tensors\n",
      "  9672.5ms [  INFO ] cleaning up resources for input tensors\n",
      "  9672.5ms [  INFO ] cleaning up resources for output tensors\n",
      " 10400.9ms [  INFO ] cleaning up resources for input tensors\n",
      " 10400.9ms [  INFO ] cleaning up resources for output tensors\n",
      " 11131.3ms [  INFO ] cleaning up resources for input tensors\n",
      " 11131.3ms [  INFO ] cleaning up resources for output tensors\n",
      " 11869.7ms [  INFO ] cleaning up resources for input tensors\n",
      " 11869.7ms [  INFO ] cleaning up resources for output tensors\n",
      " 12600.2ms [  INFO ] cleaning up resources for input tensors\n",
      " 12600.2ms [  INFO ] cleaning up resources for output tensors\n",
      " 13349.8ms [  INFO ] cleaning up resources for input tensors\n",
      " 13349.9ms [  INFO ] cleaning up resources for output tensors\n",
      " 14077.6ms [  INFO ] cleaning up resources for input tensors\n",
      " 14077.6ms [  INFO ] cleaning up resources for output tensors\n",
      " 14810.5ms [  INFO ] cleaning up resources for input tensors\n",
      " 14810.5ms [  INFO ] cleaning up resources for output tensors\n",
      " 15540.5ms [  INFO ] cleaning up resources for input tensors\n",
      " 15540.5ms [  INFO ] cleaning up resources for output tensors\n",
      " 16276.9ms [  INFO ] cleaning up resources for input tensors\n",
      " 16277.0ms [  INFO ] cleaning up resources for output tensors\n",
      " 17007.0ms [  INFO ] cleaning up resources for input tensors\n",
      " 17007.0ms [  INFO ] cleaning up resources for output tensors\n",
      " 17739.9ms [  INFO ] cleaning up resources for input tensors\n",
      " 17739.9ms [  INFO ] cleaning up resources for output tensors\n",
      " 18472.1ms [  INFO ] cleaning up resources for input tensors\n",
      " 18472.1ms [  INFO ] cleaning up resources for output tensors\n",
      " 18551.4ms [  INFO ] Freeing graphsInfo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] InitializeStderr: DebugLog initialized.\n",
      "[INFO] SNPE HTP Offline Prepare: Attempting to create cache for SM8550\n",
      "[INFO] Attempting to open dynamically linked lib: libHtpPrepare.so\n",
      "[INFO] dlopen libHtpPrepare.so SUCCESS handle 0xf873a0\n",
      "[INFO] Found Interface Provider (v2.10)\n",
      "[USER_WARNING] QnnDsp <W> Initializing HtpProvider\n",
      "[USER_WARNING] QnnDsp <W> HTP arch will be deprecated, please set SoC id instead.\n",
      "[USER_WARNING] QnnDsp <W> Cost Based unsupported on soc SM8550\n",
      "[USER_INFO] Platform option not set\n",
      "[USER_INFO] Offline Prepare VTCM size(MB) selected = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Prepared Graph's Summary ======\n",
      "Spill fill buffer size = 228982784\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[USER_INFO] Backend Mgr ~Dtor called for backend HTP\n",
      "[USER_INFO] Cleaning up Context handle:0x1\n",
      "[USER_INFO] BackendTerminate triggered\n",
      "[USER_WARNING] QnnDsp <W> Device 0x1 not found in registry\n",
      "[INFO] SNPE HTP Offline Prepare: Successfully created cache for SM8550\n",
      "[INFO] SNPE HTP Offline Prepare: Saved cached DLC to whisper_tiny_encoder_w8a16.dlc\n",
      "[USER_INFO] BackendTerminate triggered\n",
      "[INFO] DebugLog shutting down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Model HTML file saved at /local/mnt/workspace/sahinhos/sahinworkspace/aimet-model-zoo/Whisper_tiny/whisper_tiny_encoder_w8a16.html\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "\n",
    "snpe-dlc-quantize --input_dlc whisper_tiny_encoder_fp32.dlc --input_list list.txt  --optimizations cle --axis_quant --output_dlc whisper_tiny_encoder_w8a16.dlc --weights_bitwidth 8 --act_bitwidth 16 --enable_htp --htp_socs sm8550\n",
    "\n",
    "snpe-dlc-info -i whisper_tiny_encoder_w8a16.dlc > whisper_tiny_encoder_w8a16.txt\n",
    "snpe-dlc-viewer -i whisper_tiny_encoder_w8a16.dlc -s whisper_tiny_encoder_w8a16.html "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f91092d-7445-4848-9265-e75823ff2960",
   "metadata": {},
   "source": [
    "### Inferencing the FP32 Model on linux x86 machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d3a882-8c73-45ea-a4e6-e15d0f14e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf OUTPUT_Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7b2a4d-5409-42cd-8ef5-21b09c90509a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] AISW SDK environment set\n",
      "[INFO] SNPE_ROOT: /local/mnt/workspace/snpe/2.16.0.231029\n",
      "-------------------------------------------------------------------------------\n",
      "Model String: N/A\n",
      "SNPE v2.16.0.231027072756_64280\n",
      "-------------------------------------------------------------------------------\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_0.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_1.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_2.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_3.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_4.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_5.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_6.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_7.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_8.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_9.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_10.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_11.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_12.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_13.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_14.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_15.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_16.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_17.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_18.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_19.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_20.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_21.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_22.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_23.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_24.raw\n",
      "Successfully executed!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "\n",
    "snpe-net-run --container whisper_tiny_encoder_fp32.dlc --input_list list.txt --output_dir OUTPUT_Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713afd92-252a-4feb-be77-3c84b035342f",
   "metadata": {},
   "source": [
    "#### Checking the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81beaffe-8d39-4e9e-bb38-7e4e8ce5fe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Painting, he tells us, is of a different quality to mathematics, and finish in art is adding more effect.\n",
      " The little girl had been asleep, but she heard the raps and opened the door.\n",
      " by Harry Quilter MA.\n",
      " As for etchings, there are two kinds, British and foreign.\n",
      " L'Inille's pictures are a sort of upguards and atom paintings, and Mason's exquisite Idols are as national as a jingo poem. Mr. Berkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Caudier gives his sitter a cheerful slap on the back, before he says, like a shampoo or an a Turkish bath, next man,\n",
      " Because you're asleep instead of conquering, the lovely Rose princess has become a fiddle without a bow. All poor shaggy sits there, a cooling dove.\n",
      " Mr. Quilter has missed his chance, for he has failed even to make himself the tougher of painting.\n",
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.\n",
      " In fact, he is quite severe on Mr. Ruskin, for not recognizing that a picture should denote the frailty of man, and remarks with pleasing courtesy and falseness graced that many faces are feeling\n",
      " He doesn't work at all.\n",
      " Only, unfortunately, his own work never does get good.\n",
      " He has gone and gone for good, answered Paulicrom, who had managed to squeeze into the room beside the dragon, and had witnessed the occurrences with much interest.\n",
      " I hope he doesn't work too hard since she got me.\n",
      " I also offered to help your brother to escape, but he would not go.\n",
      " He laments most bitterly the divorce that has been made between decorative art and what we usually call pictures. Makes a customary appeal to the last judgment and reminds us that in the great days of art, Michael Angelo was the \"Frinishing\" Opposterer.\n",
      " Nor is Mr. Quilters' manner less interesting than his matter.\n",
      " I have remained a prisoner only because I wished to be one. And with this, he stepped forward and burst the stoutchains as easily as if they had been threads.\n",
      " He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similarly, he's drawn from eating and its results occur most readily to the mind.\n",
      " It is obviously unnecessary for us to point out how luminous these criticisms are, how delicate and expression.\n",
      " It eats and sleeps very steadily, replied the new king.\n",
      " On the general principles of art and Mr. Quilter writes with equal lucidity.\n",
      " I begged Ruggano a long ago to send him away, but he would not do so.\n",
      " The King is flooded in disgrace and your friends are asking for you.\n",
      " Near the fire, any ornaments Fred brought home from India on the mental board.\n",
      " He has grave doubts whether Sir Frederick Layton's work is really Greek after all and can discover in it but little of Rocky Ithaca.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "folder = [\"OUTPUT_Encoder\"]\n",
    "\n",
    "\n",
    "for j in range(0,1):\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            last_hidden_state = np.fromfile(result_path+'/595.raw', dtype=\"float32\")\n",
    "            \n",
    "            encoder_hidden_states=last_hidden_state.reshape((1,1500,384))\n",
    "            print(decoder_block_tflite(encoder_hidden_states))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a9e14-e402-4d10-a7b6-ce07effd2d4a",
   "metadata": {},
   "source": [
    "## Inferencing on Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6599e243-a46e-48a3-9529-9aadcfbfb933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of devices attached\n",
      "389c94f8\tdevice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "adb devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "749fb7a8-2eb6-43ef-9c08-aa59e496517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SNPE_ROOT']=\"../../../../snpe/2.16.0.231029\"#set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"input_features\"\n",
    "os.environ['FOLDER_WITH_ARTIFACTS']=\"whisper\"\n",
    "os.environ['DLCFP32']=\"whisper_tiny_encoder_fp32.dlc\"\n",
    "os.environ['DLCA8W16']=\"whisper_tiny_encoder_w8a16.dlc\"\n",
    "os.environ['TARGET_INPUT_LIST']=\"list.txt\"\n",
    "os.environ['ONDEVICE_FOLDER']=\"whisper\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"389c94f8\" #fill your device-id. Use command \"adb devices\" to get devices names. example :\"e18d5d0\"\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9eb36784-a92c-4f4c-ab4d-416d7d25c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "53bc06b3-87df-4c97-828f-3a584dc13187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libc++_shared.so: 1 file pushed. 18.8 MB/s (1027408 bytes in 0.052s)\n",
      "../../../../snpe/2.16.0.231029/bin/aarch64-android/snpe-net-run: 1 file pushed. 16.4 MB/s (381976 bytes in 0.022s)\n",
      "../../../../snpe/2.16.0.231029/lib/hexagon-v73/unsigned/libCalculator_skel.so: 1 file pushed. 0.7 MB/s (5484 bytes in 0.008s)\n",
      "../../../../snpe/2.16.0.231029/lib/hexagon-v73/unsigned/libSnpeHtpV73Skel.so: 1 file pushed. 70.5 MB/s (7069568 bytes in 0.096s)\n",
      "2 files pushed. 60.5 MB/s (7075052 bytes in 0.112s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libcalculator_htp.so: 1 file pushed. 0.8 MB/s (6416 bytes in 0.008s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libcalculator.so: 1 file pushed. 1.0 MB/s (6368 bytes in 0.006s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libc++_shared.so: 1 file pushed. 38.0 MB/s (1027408 bytes in 0.026s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libhta_hexagon_runtime_snpe.so: 1 file pushed. 56.8 MB/s (2789832 bytes in 0.047s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libPlatformValidatorShared.so: 1 file pushed. 87.1 MB/s (9561280 bytes in 0.105s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libSnpeDspV66Stub.so: 1 file pushed. 52.7 MB/s (923048 bytes in 0.017s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libSnpeHta.so: 1 file pushed. 40.0 MB/s (543424 bytes in 0.013s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libSnpeHtpPrepare.so: 1 file pushed. 101.7 MB/s (25196048 bytes in 0.236s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libSnpeHtpV68Stub.so: 1 file pushed. 11.8 MB/s (62888 bytes in 0.005s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libSnpeHtpV69Stub.so: 1 file pushed. 13.4 MB/s (63768 bytes in 0.005s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libSnpeHtpV73Stub.so: 1 file pushed. 12.5 MB/s (70008 bytes in 0.005s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libSnpeHtpV75Stub.so: 1 file pushed. 11.1 MB/s (72112 bytes in 0.006s)\n",
      "../../../../snpe/2.16.0.231029/lib/aarch64-android/libSNPE.so: 1 file pushed. 98.5 MB/s (12030584 bytes in 0.116s)\n",
      "13 files pushed. 83.1 MB/s (52353184 bytes in 0.601s)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/hexagon-v73/unsigned/*.so /data/local/tmp/snpeexample/dsp/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b88dc68-d1d9-4d3e-8425-f342bbb41d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "272f82c6-456c-4615-9d4a-e6b7d512ad5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whisper_tiny_encoder_w8a16.dlc: 1 file pushed. 71.6 MB/s (28788698 bytes in 0.384s)\n",
      "whisper_tiny_encoder_fp32.dlc: 1 file pushed. 73.8 MB/s (32936281 bytes in 0.425s)\n",
      "input_features/: 25 files pushed. 37.6 MB/s (24000000 bytes in 0.609s)\n",
      "list.txt: 1 file pushed. 0.1 MB/s (865 bytes in 0.009s)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $DLCA8W16 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLCFP32 /data/local/tmp/$ONDEVICE_FOLDER \n",
    "$DEVICE_SHELL push input_features /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $TARGET_INPUT_LIST /data/local/tmp/$ONDEVICE_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "576229af-6f36-4556-9011-4e1115f55354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------\n",
      "Model String: N/A\n",
      "SNPE v2.16.0.231027072756_64280\n",
      "-------------------------------------------------------------------------------\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_0.raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to set thread affinity for cpuset 40. errno = 22. Setting the thread affinity to cpuset f8 instead. \n",
      "WARNING: Failed to set thread affinity for cpuset 40. errno = 22. Setting the thread affinity to cpuset f8 instead. \n",
      "WARNING: Failed to set thread affinity for cpuset 40. errno = 22. Setting the thread affinity to cpuset f8 instead. \n",
      "WARNING: Failed to set thread affinity for cpuset 40. errno = 22. Setting the thread affinity to cpuset f8 instead. \n",
      "WARNING: Failed to set thread affinity for cpuset 40. errno = 22. Setting the thread affinity to cpuset f8 instead. \n",
      "WARNING: Failed to set thread affinity for cpuset 40. errno = 22. Setting the thread affinity to cpuset f8 instead. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DNN input(s):\n",
      "input_features/inp_val_1.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_2.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_3.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_4.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_5.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_6.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_7.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_8.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_9.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_10.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_11.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_12.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_13.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_14.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_15.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_16.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_17.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_18.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_19.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_20.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_21.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_22.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_23.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_24.raw\n",
      "Successfully executed!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "chmod -R 777 /data/local/tmp/snpeexample\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_32b_CPU\n",
    "export OUTPUT_DLC_32=whisper_tiny_encoder_fp32.dlc\n",
    "export ONDEVICE_FOLDER=\"whisper\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $OUTPUT_DLC_32 --input_list list.txt   --output_dir $OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "11cb0d0d-3ce5-4bef-bab5-e66992176d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Fallback is enabled with floating point execution mode.\n",
      "-------------------------------------------------------------------------------\n",
      "Model String: N/A\n",
      "SNPE v2.16.0.231027072756_64280\n",
      "-------------------------------------------------------------------------------\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_0.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_1.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_2.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_3.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_4.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_5.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_6.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_7.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_8.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_9.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_10.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_11.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_12.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_13.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_14.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_15.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_16.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_17.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_18.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_19.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_20.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_21.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_22.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_23.raw\n",
      "Processing DNN input(s):\n",
      "input_features/inp_val_24.raw\n",
      "Successfully executed!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "chmod -R 777 /data/local/tmp/snpeexample\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/aarch64-android/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/aarch64-android/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_DSP_W8A16\n",
    "export DLC_W8A16=whisper_tiny_encoder_w8a16.dlc\n",
    "export ONDEVICE_FOLDER=\"whisper\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $DLC_W8A16 --input_list list.txt  --output_dir $OUTPUT_FOLDER --use_dsp --enable_cpu_fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4b20e04a-e843-4196-9fed-dd2b0b68a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf OUTPUT_32b_CPU/\n",
    "rm -rf OUTPUT_DSP_W8A16/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8b2a523-8846-4424-b244-aceaf8e5dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/local/tmp/whisper/OUTPUT_DSP_W8A16/: 27 files pulled. 47.1 MB/s (58524760 bytes in 1.185s)\n",
      "/data/local/tmp/whisper/OUTPUT_32b_CPU/: 27 files pulled. 46.3 MB/s (58320296 bytes in 1.201s)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_DSP_W8A16 OUTPUT_DSP_W8A16\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_32b_CPU OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f76b3-bef7-4723-86e6-07c3ace34ce3",
   "metadata": {},
   "source": [
    "### Checking the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a3381f12-6f20-42c8-aea2-7dddd8086ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------OUTPUT_32b_CPU------------------------------\n",
      " Painting he tells us is of a different quality to mathematics and finish in art is adding more effect.\n",
      " The little girl had been asleep, but she heard the raps and opened the door.\n",
      " by Harry Quilter MA.\n",
      " As for etchings, there are two kinds, British and foreign.\n",
      " Lennils, pictures are a sort of upguards and atom paintings, and Mason's exquisite Idols are as national as a jingo poem. Mr. Birkut Foster's landscapes smile at one much in the same way that Mr. Karker used to flash his teeth. And Mr. John Colier gives his sitter a cheerful slap on the back before he says, like a shampoo or a turkish bath, next man,\n",
      " Because you are asleep instead of conquering, the lovely Rose Princess has become a fiddle without a bow. While poor Shaggy sits there, a cooling dove.\n",
      " Mr. Kulter has missed his chance, for he has failed even to make himself the tougher of painting.\n",
      " Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.\n",
      " In fact, he is quite severe on Mr. Ruskin, for not recognizing that a picture should denote the frailty of man. And remarks with pleasing courtesy and falseness graced that many phases of feeling\n",
      " He doesn't work at all.\n",
      " Only, unfortunately, his own work never does get good.\n",
      " He has gone and gone for good answered Paul Icrom who had managed to squeeze into the room beside the dragon and had witnessed the occurrences with much interest.\n",
      " I hope he doesn't work too hard since she got me.\n",
      " I also offered to help your brother to escape, but he would not go.\n",
      " He laments most bitterly the divorce that has been made between decorative art and what we usually call pictures makes a customary appeal to the last judgment and reminds us that in the great days of art Michael Angelov was the furnishing apostorer.\n",
      " Nor is Mr. Quilters' manner less interesting than his matter.\n",
      " I have remained a prisoner only because I wished to be one. And with this, he stepped forward and burst the stoutchains as easily as if they had been threads.\n",
      " He tells us that at this festive season of the year with Christmas and roast beef looming before us, similarly drawn from eating and its results occur most readily to the mind.\n",
      " It is obviously unnecessary for us to point out how luminous these criticisms are, how delicate and expression.\n",
      " It eats and sleeps very steadily, replied the new king.\n",
      " On the general principles of art and Mr. Quilter writes with equal lucidity.\n",
      " I begged Ruggano a long ago to send him away, but he would not do so.\n",
      " The king is flooded disgrace and your friends are asking for you.\n",
      " Near the fire, any ornaments Fred brought home from India on the mental board.\n",
      " He has grave doubts whether Sir Frederick Layton's work is really Greek after all and can discover in it but little of Rocky Ithaca.\n",
      "------------------------------OUTPUT_DSP_W8A16------------------------------\n",
      " Painting he tells us is of a different quality to mathematics and finish in art is adding more fact\n",
      " The little girl had been asleep, but she heard the raps and opened the door.\n",
      " by Harry Quilter MA.\n",
      " As for etchings, there are two kinds, British and foreign.\n",
      " Lennils, pictures are a sort of upguards and atom paintings, and Mason's exquisite itals are as national as a jingo poem. Mr. Birkut Foster's landscapes smile at one much in the same way that Mr. Karker used to flash his teeth. And Mr. John Kalior gives his sitter a cheerful slap on the back before he says, like a shampoo or a turkish bath. Next man,\n",
      " Because he was sleeping instead of conquering, the lovely rose princess has become a fiddle without a bow. All poor shaggy sits there, a cooling dove.\n",
      " Mr. Kulter has missed his chance. For he has failed even to make himself the tougher of painting.\n",
      " Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.\n",
      " In fact, he is quite severe on Mr. Ruskin, for not recognizing that a picture should denote the frailty of man. And remarks with pleasing courtesy and falseness graced that many phases of feeling\n",
      " He doesn't work at all.\n",
      " Only, unfortunately, his own work never does get good.\n",
      " He has gone and gone for good. answered Paul Icrom, who had managed to squeeze into the room beside the dragon and had witnessed the occurrences with much interest.\n",
      " I hope he doesn't work too hard since she got me.\n",
      " I also offered to help your brother to escape, but he would not go.\n",
      " He laments most bitterly the divorce that has been made between decorative art and what we usually call pictures makes a customary appeal to the last judgment and reminds us that in the great days of art Michaelangelo was the furnishing apostorer.\n",
      " Nor is Mr. Quilters' manner less interesting than his matter.\n",
      " I have remained a prisoner only because I wished to be one. And with this, he stepped forward and burst the stoutchains as easily as if they had been threads.\n",
      " He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similarly drawn from eating and its results occur most readily to the mind.\n",
      " It is obviously unnecessary for us to point out how luminous these criticisms are, how delicate and expression.\n",
      " It eats and sleeps very steadily, replied the new king.\n",
      " On the general principles of art and Mr. Quilter writes with equal lucidity.\n",
      " I begged Ruggano a long ago to send him away, but he would not do so.\n",
      " The king is flooded disgrace and your friends are asking for you.\n",
      " near the fire, and the ornaments Fred brought home from India on the mental board.\n",
      " He has grave doubts whether Sir Frederick Latins' work is really Greek after all and can discover in it but little of Rocky Ithaca.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "folder = [\"OUTPUT_32b_CPU\",\"OUTPUT_DSP_W8A16\"]\n",
    "\n",
    "\n",
    "for j in range(0,2):\n",
    "    print(\"------------------------------\"+folder[j]+\"------------------------------\")\n",
    "    for result_path in glob.glob(os.path.join(folder[j], '*')):\n",
    "        if \".log\" not in result_path:\n",
    "            last_hidden_state = np.fromfile(result_path+'/595.raw', dtype=\"float32\")\n",
    "            \n",
    "            encoder_hidden_states=last_hidden_state.reshape((1,1500,384))\n",
    "            print(decoder_block_onnx(encoder_hidden_states))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a1ad9-55d1-4466-b50d-b07699524533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
