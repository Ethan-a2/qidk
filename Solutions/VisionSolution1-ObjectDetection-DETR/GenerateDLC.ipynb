{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94b4143-7c12-4f89-9b4f-459f053b6050",
   "metadata": {},
   "source": [
    "# Setting Up SDK Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1748bf-bc9a-4a9f-9ece-55dcfa54705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SNPE_ROOT']=\"/opt/qcom/aistack/qairt/2.25.0.240728\" #set up your snpe path here.\n",
    "os.environ['RAW_FILE_FOLDER']=\"raw\"\n",
    "os.environ['DLC32']=\"models/detr_resnet101_fp32.dlc\"  # Use the path to your non-quantized dlc\n",
    "os.environ['DLC8']=\"models/detr_resnet101_w8a8.dlc\"              # Use the path to your Quantized dlc\n",
    "os.environ['TARGET_INPUT_LIST']=\"list.txt\"  # Use the name of the input file\n",
    "os.environ['ONDEVICE_FOLDER']=\"detr\"\n",
    "os.environ['DEVICE_HOST']=\"localhost\"\n",
    "os.environ['DEVICE_ID']=\"503bd507\" #fill your device-id. Use command \"adb devices\" to get devices names. example :\"e18d5d0\"\n",
    "os.environ['SNPE_TARGET_ARCH']=\"aarch64-android\"\n",
    "os.environ['SNPE_TARGET_STL']=\"libc++_shared.so\"\n",
    "os.environ['SNPE_TARGET_DSPARCH']=\"hexagon-v75\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe506ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/liuqi/code/qnn/qidk/Solutions/VisionSolution1-ObjectDetection-DETR\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"/media/code/qnn/qidk/Solutions/VisionSolution1-ObjectDetection-DETR\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f140a00d-4a8e-419b-975a-a6a6810ac76e",
   "metadata": {},
   "source": [
    "## Generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6cd0a42-b02b-4013-88f3-8e417729c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/liuqi/.cache/torch/hub/facebookresearch_detr_main\n",
      "/home/liuqi/.cache/torch/hub/facebookresearch_detr_main/models/position_encoding.py:41: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 92])\n",
      "torch.Size([100, 91])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "model = torch.hub.load('facebookresearch/detr', 'detr_resnet101', pretrained=True)\n",
    "model.eval()\n",
    "dummy_input=torch.randn(1, 3, 800, 1066)\n",
    "output = model(dummy_input)\n",
    "print(output['pred_logits'].shape)\n",
    "\n",
    "class ModifiedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModifiedModel,self).__init__()\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "    def forward(self,pixel_values):\n",
    "        output = self.model(pixel_values)\n",
    "        output['pred_logits'] = output['pred_logits'].softmax(-1)[0,:,:-1]\n",
    "        return output\n",
    "customModel = ModifiedModel()\n",
    "customModel.eval()\n",
    "dummy_input=torch.randn(1, 3, 800, 1066)\n",
    "output = customModel(dummy_input)\n",
    "print(output['pred_logits'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450758bd-a367-4d2c-9bb0-d2ea60704f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05945e74-19fc-4f96-8fc3-a938769db6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuqi/.cache/torch/hub/facebookresearch_detr_main/util/misc.py:338: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  max_size_i = torch.max(torch.stack([img.shape[i] for img in tensor_list]).to(torch.float32)).to(torch.int64)\n",
      "/home/liuqi/.cache/torch/hub/facebookresearch_detr_main/util/misc.py:348: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for img in tensor_list:\n"
     ]
    }
   ],
   "source": [
    "dummy_input=torch.randn(1, 3, 800, 1066)\n",
    "\n",
    "torch.onnx.export(customModel, dummy_input, \"models/detr_resnet101.onnx\", opset_version=11\n",
    "                  , verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef0d26e-d0b2-413f-99d9-fb9488edf021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] AISW SDK environment set\n",
      "[INFO] QNN_SDK_ROOT: /opt/qcom/aistack/qairt/2.25.0.240728\n",
      "[INFO] SNPE_ROOT: /opt/qcom/aistack/qairt/2.25.0.240728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 12:12:51,550 - 235 - INFO - Simplified model validation is successful\n",
      "2025-02-27 12:13:02,194 - 235 - INFO - INFO_INITIALIZATION_SUCCESS: \n",
      "2025-02-27 12:13:02,747 - 235 - INFO - INFO_CONVERSION_SUCCESS: Conversion completed successfully\n",
      "2025-02-27 12:13:03,253 - 235 - INFO - INFO_WRITE_SUCCESS: \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-onnx-to-dlc --input_network models/detr_resnet101.onnx --output_path models/detr_resnet101_fp32.dlc\n",
    "snpe-dlc-info -i models/detr_resnet101_fp32.dlc > models/detr_resnet101_fp32.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6259dc-4d98-4358-8456-1ea9e353f192",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac5270dc-c0c9-4e3f-8403-5ed4f92b66f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: ipywidgets in /home/liuqi/.local/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/liuqi/.local/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/liuqi/.local/lib/python3.10/site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/liuqi/.local/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/liuqi/.local/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/liuqi/.local/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /home/liuqi/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /home/liuqi/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/liuqi/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/liuqi/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/liuqi/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/liuqi/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/micromamba/envs/py10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/liuqi/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/liuqi/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/liuqi/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/liuqi/.local/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/liuqi/.local/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/liuqi/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/liuqi/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/liuqi/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision.models import resnet50\n",
    "import torchvision.transforms as T\n",
    "torch.set_grad_enabled(False);\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "import glob\n",
    "import torch.nn.functional as nnf\n",
    "import subprocess\n",
    "!pip3 install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289295b0-7a9b-4de6-a02b-9435acf52897",
   "metadata": {},
   "source": [
    "## Getting the Dataset and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54d07d1-8210-480d-bec3-746e21c4c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User can download dataset of their choice for accuracy validation. \n",
    "# User needs to follow the pre/post processing steps prescribed in dataset (or) given below. \n",
    "# You can use coco val2017 or part of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e581c6c-3fe2-493a-a99f-26feda92c17b",
   "metadata": {},
   "source": [
    "### Pre-Processing Steps of DETR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ddb6093-42b4-45c2-8c3e-d12d22d6381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard PyTorch mean-std input image normalization\n",
    "transform = T.Compose([\n",
    "    T.Resize(800),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b\n",
    "\n",
    "def plot_results(pil_img, prob, boxes,Image_count):\n",
    "    fig=plt.figure(figsize=(8,8))\n",
    "    ax1=fig.add_subplot(2,2,3)\n",
    "    ax1.imshow(pil_img)\n",
    "    ax = plt.gca()\n",
    "    colors = COLORS * 100\n",
    "    for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
    "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                   fill=False, color=c, linewidth=1))\n",
    "        cl = p.argmax()\n",
    "        text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n",
    "        ax.text(xmin, ymin, text, fontsize=10,\n",
    "                bbox=dict(alpha=0.5))\n",
    "    plt.savefig(str(Image_count)+\".jpg\")\n",
    "    if Image_count%2==0:\n",
    "        shutil.move(str(Image_count)+\".jpg\",\"output/CPU\")\n",
    "    else:\n",
    "        shutil.move(str(Image_count)+\".jpg\",\"output/DSP\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc8c1b1-55b7-4cd5-b26a-cf17d737e1ae",
   "metadata": {},
   "source": [
    "### Steps to create raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d14b0aba-9d06-4f91-98d5-4a17b2127c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘raw’: File exists\n"
     ]
    }
   ],
   "source": [
    "#黑白图会转失败，少转一些也没关系。\n",
    "name=\"raw\"\n",
    "os.system('mkdir ' + name)\n",
    "def detect(imgfile,i):\n",
    "    # print('imgfile:', imgfile)\n",
    "    #getting the actual image\n",
    "    origimg = Image.open(imgfile)\n",
    "    #Transforming the image\n",
    "    img = transform(origimg).unsqueeze(0)\n",
    "\n",
    "    img= nnf.interpolate(img, size=(800, 1066), mode='bicubic', align_corners=False)\n",
    "    \n",
    "    img_to_save=img.numpy().transpose(0,2,3,1).astype(np.float32)\n",
    "    \n",
    "    img_to_save.tofile(\"raw/\"+filenames[i].split(\".\")[0]+\".raw\")\n",
    "    \n",
    "filenames = os.listdir(\"val2017\") ## change val2017 to the folder name where you have your dataset images.\n",
    "for i in range(0,len(filenames)):\n",
    "    if \"jpg\" in filenames[i].lower():\n",
    "        detect(\"val2017/\"+filenames[i],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5992e8ce-c6df-4169-979e-b000e7943fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "find ./raw -name *.raw > list.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57404ad6-9bcf-4254-9ae7-902e34b80196",
   "metadata": {},
   "source": [
    "### Getting the Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2e6d39d-06ce-4c5b-a5c5-1a08a51fd491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] AISW SDK environment set\n",
      "[INFO] QNN_SDK_ROOT: /opt/qcom/aistack/qairt/2.25.0.240728\n",
      "[INFO] SNPE_ROOT: /opt/qcom/aistack/qairt/2.25.0.240728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] InitializeStderr: DebugLog initialized.\n",
      "[INFO] Processed command-line arguments\n",
      "[INFO] Quantized parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.5ms [  INFO ] Inferences will run in sync mode\n",
      "     1.2ms [  INFO ] Initializing logging in the backend. Callback: [0x557288fb2b60], Log Level: [3]\n",
      "     1.3ms [  INFO ] No BackendExtensions lib provided;initializing NetRunBackend Interface\n",
      "     0.6ms [  INFO ] [QNN_CPU] CpuBackend creation start\n",
      "     0.6ms [  INFO ] [QNN_CPU] CpuBackend creation end\n",
      "     1.9ms [WARNING] Unable to find a device with NetRunDeviceKeyDefault in Library NetRunBackendLibKeyDefault\n",
      "     1.9ms [WARNING] Profile Logger with name = defaultKey doesn't exist! Returning nullptr\n",
      "     0.8ms [  INFO ] [QNN_CPU] QnnContext create start\n",
      "     0.8ms [  INFO ] [QNN_CPU] QnnContext create end\n",
      "     2.7ms [  INFO ] Entering QuantizeRuntimeApp flow\n",
      "     2.7ms [WARNING] Profile Logger with name = defaultKey doesn't exist! Returning nullptr\n",
      "     1.5ms [  INFO ] [QNN_CPU] CpuGraph creation start\n",
      "     1.7ms [  INFO ] [QNN_CPU] CpuGraph creation end\n",
      "     1.7ms [  INFO ] [QNN_CPU] QnnGraph create end\n",
      "   130.7ms [  INFO ] [QNN_CPU] QnnGraph finalize start\n",
      "   211.8ms [  INFO ] [QNN_CPU] QnnGraph finalize end\n",
      "   218.0ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "  4113.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "  4119.0ms [  INFO ] cleaning up resources for input tensors\n",
      "  4119.1ms [  INFO ] cleaning up resources for output tensors\n",
      "  4130.3ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "  7950.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "  7953.1ms [  INFO ] cleaning up resources for input tensors\n",
      "  7953.1ms [  INFO ] cleaning up resources for output tensors\n",
      "  7967.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 11459.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 11462.6ms [  INFO ] cleaning up resources for input tensors\n",
      " 11462.6ms [  INFO ] cleaning up resources for output tensors\n",
      " 11472.0ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 15014.9ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 15016.9ms [  INFO ] cleaning up resources for input tensors\n",
      " 15016.9ms [  INFO ] cleaning up resources for output tensors\n",
      " 15026.4ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 18461.9ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 18464.2ms [  INFO ] cleaning up resources for input tensors\n",
      " 18464.2ms [  INFO ] cleaning up resources for output tensors\n",
      " 18474.5ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 22096.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 22098.7ms [  INFO ] cleaning up resources for input tensors\n",
      " 22098.7ms [  INFO ] cleaning up resources for output tensors\n",
      " 22108.2ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 25682.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 25683.7ms [  INFO ] cleaning up resources for input tensors\n",
      " 25683.7ms [  INFO ] cleaning up resources for output tensors\n",
      " 25692.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 29376.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 29375.7ms [  INFO ] cleaning up resources for input tensors\n",
      " 29375.7ms [  INFO ] cleaning up resources for output tensors\n",
      " 29384.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 33469.1ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 33468.8ms [  INFO ] cleaning up resources for input tensors\n",
      " 33468.8ms [  INFO ] cleaning up resources for output tensors\n",
      " 33479.3ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 37859.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 37859.2ms [  INFO ] cleaning up resources for input tensors\n",
      " 37859.2ms [  INFO ] cleaning up resources for output tensors\n",
      " 37871.4ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 41893.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 41893.0ms [  INFO ] cleaning up resources for input tensors\n",
      " 41893.0ms [  INFO ] cleaning up resources for output tensors\n",
      " 41902.5ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 45568.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 45568.1ms [  INFO ] cleaning up resources for input tensors\n",
      " 45568.1ms [  INFO ] cleaning up resources for output tensors\n",
      " 45577.3ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 49233.4ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 49233.7ms [  INFO ] cleaning up resources for input tensors\n",
      " 49233.7ms [  INFO ] cleaning up resources for output tensors\n",
      " 49244.1ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 53079.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 53079.7ms [  INFO ] cleaning up resources for input tensors\n",
      " 53079.7ms [  INFO ] cleaning up resources for output tensors\n",
      " 53089.9ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 57008.3ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 57007.8ms [  INFO ] cleaning up resources for input tensors\n",
      " 57007.8ms [  INFO ] cleaning up resources for output tensors\n",
      " 57016.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 60910.9ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 60910.5ms [  INFO ] cleaning up resources for input tensors\n",
      " 60910.5ms [  INFO ] cleaning up resources for output tensors\n",
      " 60920.3ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 64867.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 64868.4ms [  INFO ] cleaning up resources for input tensors\n",
      " 64868.5ms [  INFO ] cleaning up resources for output tensors\n",
      " 64882.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 68839.9ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 68839.1ms [  INFO ] cleaning up resources for input tensors\n",
      " 68839.1ms [  INFO ] cleaning up resources for output tensors\n",
      " 68848.9ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 72802.9ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 72802.9ms [  INFO ] cleaning up resources for input tensors\n",
      " 72802.9ms [  INFO ] cleaning up resources for output tensors\n",
      " 72815.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 76703.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 76703.7ms [  INFO ] cleaning up resources for input tensors\n",
      " 76703.7ms [  INFO ] cleaning up resources for output tensors\n",
      " 76714.5ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 80471.3ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 80470.9ms [  INFO ] cleaning up resources for input tensors\n",
      " 80470.9ms [  INFO ] cleaning up resources for output tensors\n",
      " 80480.5ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 84462.6ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 84461.8ms [  INFO ] cleaning up resources for input tensors\n",
      " 84461.8ms [  INFO ] cleaning up resources for output tensors\n",
      " 84472.1ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 88576.1ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 88576.2ms [  INFO ] cleaning up resources for input tensors\n",
      " 88576.2ms [  INFO ] cleaning up resources for output tensors\n",
      " 88586.2ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 92627.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 92627.5ms [  INFO ] cleaning up resources for input tensors\n",
      " 92627.5ms [  INFO ] cleaning up resources for output tensors\n",
      " 92637.5ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      " 96333.1ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      " 96333.0ms [  INFO ] cleaning up resources for input tensors\n",
      " 96333.0ms [  INFO ] cleaning up resources for output tensors\n",
      " 96343.4ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "100132.6ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "100132.0ms [  INFO ] cleaning up resources for input tensors\n",
      "100132.1ms [  INFO ] cleaning up resources for output tensors\n",
      "100141.5ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "103642.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "103642.6ms [  INFO ] cleaning up resources for input tensors\n",
      "103642.6ms [  INFO ] cleaning up resources for output tensors\n",
      "103652.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "107611.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "107611.4ms [  INFO ] cleaning up resources for input tensors\n",
      "107611.4ms [  INFO ] cleaning up resources for output tensors\n",
      "107621.3ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "111235.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "111235.3ms [  INFO ] cleaning up resources for input tensors\n",
      "111235.3ms [  INFO ] cleaning up resources for output tensors\n",
      "111245.0ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "114842.4ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "114842.0ms [  INFO ] cleaning up resources for input tensors\n",
      "114842.0ms [  INFO ] cleaning up resources for output tensors\n",
      "114851.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "118895.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "118894.3ms [  INFO ] cleaning up resources for input tensors\n",
      "118894.3ms [  INFO ] cleaning up resources for output tensors\n",
      "118904.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "122724.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "122724.3ms [  INFO ] cleaning up resources for input tensors\n",
      "122724.3ms [  INFO ] cleaning up resources for output tensors\n",
      "122734.4ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "126350.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "126349.5ms [  INFO ] cleaning up resources for input tensors\n",
      "126349.5ms [  INFO ] cleaning up resources for output tensors\n",
      "126358.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "130153.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "130153.0ms [  INFO ] cleaning up resources for input tensors\n",
      "130153.0ms [  INFO ] cleaning up resources for output tensors\n",
      "130163.5ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "134238.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "134239.4ms [  INFO ] cleaning up resources for input tensors\n",
      "134239.4ms [  INFO ] cleaning up resources for output tensors\n",
      "134250.2ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "138284.1ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "138283.8ms [  INFO ] cleaning up resources for input tensors\n",
      "138283.8ms [  INFO ] cleaning up resources for output tensors\n",
      "138294.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "142497.6ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "142497.1ms [  INFO ] cleaning up resources for input tensors\n",
      "142497.1ms [  INFO ] cleaning up resources for output tensors\n",
      "142506.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "146350.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "146350.5ms [  INFO ] cleaning up resources for input tensors\n",
      "146350.5ms [  INFO ] cleaning up resources for output tensors\n",
      "146361.1ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "150432.3ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "150432.7ms [  INFO ] cleaning up resources for input tensors\n",
      "150432.7ms [  INFO ] cleaning up resources for output tensors\n",
      "150443.2ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "154196.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "154195.9ms [  INFO ] cleaning up resources for input tensors\n",
      "154195.9ms [  INFO ] cleaning up resources for output tensors\n",
      "154206.1ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "158402.2ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "158401.7ms [  INFO ] cleaning up resources for input tensors\n",
      "158401.7ms [  INFO ] cleaning up resources for output tensors\n",
      "158411.5ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "162182.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "162182.0ms [  INFO ] cleaning up resources for input tensors\n",
      "162182.0ms [  INFO ] cleaning up resources for output tensors\n",
      "162192.2ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "165879.6ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "165879.5ms [  INFO ] cleaning up resources for input tensors\n",
      "165879.6ms [  INFO ] cleaning up resources for output tensors\n",
      "165890.9ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "169565.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "169565.4ms [  INFO ] cleaning up resources for input tensors\n",
      "169565.4ms [  INFO ] cleaning up resources for output tensors\n",
      "169574.7ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "173643.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "173643.4ms [  INFO ] cleaning up resources for input tensors\n",
      "173643.4ms [  INFO ] cleaning up resources for output tensors\n",
      "173653.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "177770.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "177770.4ms [  INFO ] cleaning up resources for input tensors\n",
      "177770.4ms [  INFO ] cleaning up resources for output tensors\n",
      "177780.3ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "181554.9ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "181554.1ms [  INFO ] cleaning up resources for input tensors\n",
      "181554.1ms [  INFO ] cleaning up resources for output tensors\n",
      "181564.1ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "185136.2ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "185136.0ms [  INFO ] cleaning up resources for input tensors\n",
      "185136.0ms [  INFO ] cleaning up resources for output tensors\n",
      "185145.9ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "189350.6ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "189351.1ms [  INFO ] cleaning up resources for input tensors\n",
      "189351.1ms [  INFO ] cleaning up resources for output tensors\n",
      "189362.5ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "193219.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "193218.9ms [  INFO ] cleaning up resources for input tensors\n",
      "193219.0ms [  INFO ] cleaning up resources for output tensors\n",
      "193229.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "197031.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "197031.3ms [  INFO ] cleaning up resources for input tensors\n",
      "197031.4ms [  INFO ] cleaning up resources for output tensors\n",
      "197040.7ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "200680.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "200680.3ms [  INFO ] cleaning up resources for input tensors\n",
      "200680.3ms [  INFO ] cleaning up resources for output tensors\n",
      "200693.4ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "204397.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "204397.4ms [  INFO ] cleaning up resources for input tensors\n",
      "204397.4ms [  INFO ] cleaning up resources for output tensors\n",
      "204407.3ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "208565.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "208564.5ms [  INFO ] cleaning up resources for input tensors\n",
      "208564.5ms [  INFO ] cleaning up resources for output tensors\n",
      "208574.9ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "212519.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "212518.8ms [  INFO ] cleaning up resources for input tensors\n",
      "212518.8ms [  INFO ] cleaning up resources for output tensors\n",
      "212528.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "216439.2ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "216439.0ms [  INFO ] cleaning up resources for input tensors\n",
      "216439.0ms [  INFO ] cleaning up resources for output tensors\n",
      "216449.1ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "220448.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "220448.0ms [  INFO ] cleaning up resources for input tensors\n",
      "220448.0ms [  INFO ] cleaning up resources for output tensors\n",
      "220457.9ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "224531.6ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "224531.1ms [  INFO ] cleaning up resources for input tensors\n",
      "224531.1ms [  INFO ] cleaning up resources for output tensors\n",
      "224541.1ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "228387.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "228386.7ms [  INFO ] cleaning up resources for input tensors\n",
      "228386.7ms [  INFO ] cleaning up resources for output tensors\n",
      "228396.9ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "232296.2ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "232296.4ms [  INFO ] cleaning up resources for input tensors\n",
      "232296.5ms [  INFO ] cleaning up resources for output tensors\n",
      "232306.5ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "236377.3ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "236376.9ms [  INFO ] cleaning up resources for input tensors\n",
      "236377.0ms [  INFO ] cleaning up resources for output tensors\n",
      "236388.4ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "240330.9ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "240330.2ms [  INFO ] cleaning up resources for input tensors\n",
      "240330.2ms [  INFO ] cleaning up resources for output tensors\n",
      "240343.1ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "244430.1ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "244429.4ms [  INFO ] cleaning up resources for input tensors\n",
      "244429.4ms [  INFO ] cleaning up resources for output tensors\n",
      "244439.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "248737.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "248737.0ms [  INFO ] cleaning up resources for input tensors\n",
      "248737.0ms [  INFO ] cleaning up resources for output tensors\n",
      "248749.3ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "253300.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "253299.7ms [  INFO ] cleaning up resources for input tensors\n",
      "253299.7ms [  INFO ] cleaning up resources for output tensors\n",
      "253310.2ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "257353.1ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "257352.4ms [  INFO ] cleaning up resources for input tensors\n",
      "257352.4ms [  INFO ] cleaning up resources for output tensors\n",
      "257362.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "261237.1ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "261237.1ms [  INFO ] cleaning up resources for input tensors\n",
      "261237.1ms [  INFO ] cleaning up resources for output tensors\n",
      "261250.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "265311.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "265311.4ms [  INFO ] cleaning up resources for input tensors\n",
      "265311.4ms [  INFO ] cleaning up resources for output tensors\n",
      "265321.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "269229.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "269229.4ms [  INFO ] cleaning up resources for input tensors\n",
      "269229.4ms [  INFO ] cleaning up resources for output tensors\n",
      "269240.9ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "273223.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "273222.4ms [  INFO ] cleaning up resources for input tensors\n",
      "273222.4ms [  INFO ] cleaning up resources for output tensors\n",
      "273233.1ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "277590.9ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "277591.2ms [  INFO ] cleaning up resources for input tensors\n",
      "277591.2ms [  INFO ] cleaning up resources for output tensors\n",
      "277602.2ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "281332.9ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "281332.2ms [  INFO ] cleaning up resources for input tensors\n",
      "281332.2ms [  INFO ] cleaning up resources for output tensors\n",
      "281342.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "285380.4ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "285380.2ms [  INFO ] cleaning up resources for input tensors\n",
      "285380.2ms [  INFO ] cleaning up resources for output tensors\n",
      "285394.2ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "289436.4ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "289436.5ms [  INFO ] cleaning up resources for input tensors\n",
      "289436.6ms [  INFO ] cleaning up resources for output tensors\n",
      "289446.2ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "293689.6ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "293689.2ms [  INFO ] cleaning up resources for input tensors\n",
      "293689.2ms [  INFO ] cleaning up resources for output tensors\n",
      "293698.9ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "297763.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "297763.1ms [  INFO ] cleaning up resources for input tensors\n",
      "297763.1ms [  INFO ] cleaning up resources for output tensors\n",
      "297773.0ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "301458.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "301457.3ms [  INFO ] cleaning up resources for input tensors\n",
      "301457.3ms [  INFO ] cleaning up resources for output tensors\n",
      "301469.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "305349.2ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "305348.7ms [  INFO ] cleaning up resources for input tensors\n",
      "305348.7ms [  INFO ] cleaning up resources for output tensors\n",
      "305358.4ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "309457.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "309457.1ms [  INFO ] cleaning up resources for input tensors\n",
      "309457.1ms [  INFO ] cleaning up resources for output tensors\n",
      "309467.4ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "313832.1ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "313831.6ms [  INFO ] cleaning up resources for input tensors\n",
      "313831.6ms [  INFO ] cleaning up resources for output tensors\n",
      "313845.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "318018.1ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "318018.3ms [  INFO ] cleaning up resources for input tensors\n",
      "318018.3ms [  INFO ] cleaning up resources for output tensors\n",
      "318028.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "322153.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "322153.6ms [  INFO ] cleaning up resources for input tensors\n",
      "322153.6ms [  INFO ] cleaning up resources for output tensors\n",
      "322164.7ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "325827.9ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "325827.6ms [  INFO ] cleaning up resources for input tensors\n",
      "325827.6ms [  INFO ] cleaning up resources for output tensors\n",
      "325838.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "329924.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "329924.0ms [  INFO ] cleaning up resources for input tensors\n",
      "329924.0ms [  INFO ] cleaning up resources for output tensors\n",
      "329935.0ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "333882.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "333881.3ms [  INFO ] cleaning up resources for input te"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Generated activations\n",
      "[INFO] Saved quantized dlc to: models/detr_resnet101_w8a8.dlc\n",
      "[INFO] DebugLog shutting down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsors\n",
      "333881.3ms [  INFO ] cleaning up resources for output tensors\n",
      "333892.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "337777.3ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "337776.5ms [  INFO ] cleaning up resources for input tensors\n",
      "337776.5ms [  INFO ] cleaning up resources for output tensors\n",
      "337786.3ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "341769.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "341769.7ms [  INFO ] cleaning up resources for input tensors\n",
      "341769.7ms [  INFO ] cleaning up resources for output tensors\n",
      "341780.2ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "345900.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "345899.9ms [  INFO ] cleaning up resources for input tensors\n",
      "345899.9ms [  INFO ] cleaning up resources for output tensors\n",
      "345910.0ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "349483.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "349483.5ms [  INFO ] cleaning up resources for input tensors\n",
      "349483.5ms [  INFO ] cleaning up resources for output tensors\n",
      "349494.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "353757.7ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "353757.5ms [  INFO ] cleaning up resources for input tensors\n",
      "353757.5ms [  INFO ] cleaning up resources for output tensors\n",
      "353768.8ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "357583.5ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "357583.0ms [  INFO ] cleaning up resources for input tensors\n",
      "357583.0ms [  INFO ] cleaning up resources for output tensors\n",
      "357594.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "361598.4ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "361598.1ms [  INFO ] cleaning up resources for input tensors\n",
      "361598.1ms [  INFO ] cleaning up resources for output tensors\n",
      "361608.9ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "365548.9ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "365549.1ms [  INFO ] cleaning up resources for input tensors\n",
      "365549.1ms [  INFO ] cleaning up resources for output tensors\n",
      "365560.3ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "369537.2ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "369536.8ms [  INFO ] cleaning up resources for input tensors\n",
      "369536.8ms [  INFO ] cleaning up resources for output tensors\n",
      "369546.6ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "373214.3ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "373214.0ms [  INFO ] cleaning up resources for input tensors\n",
      "373214.0ms [  INFO ] cleaning up resources for output tensors\n",
      "373224.4ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "377113.8ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "377113.6ms [  INFO ] cleaning up resources for input tensors\n",
      "377113.6ms [  INFO ] cleaning up resources for output tensors\n",
      "377125.0ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "380944.0ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "380944.9ms [  INFO ] cleaning up resources for input tensors\n",
      "380944.9ms [  INFO ] cleaning up resources for output tensors\n",
      "380955.2ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "384644.1ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "384644.0ms [  INFO ] cleaning up resources for input tensors\n",
      "384644.0ms [  INFO ] cleaning up resources for output tensors\n",
      "384655.7ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "388693.6ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "388693.3ms [  INFO ] cleaning up resources for input tensors\n",
      "388693.3ms [  INFO ] cleaning up resources for output tensors\n",
      "388704.5ms [  INFO ] [QNN_CPU] QnnGraph execute start\n",
      "392847.6ms [  INFO ] [QNN_CPU] QnnGraph execute end\n",
      "392846.9ms [  INFO ] cleaning up resources for input tensors\n",
      "392846.9ms [  INFO ] cleaning up resources for output tensors\n",
      "393457.0ms [  INFO ] Freeing graphsInfo\n",
      "393457.1ms [WARNING] Profile Logger with name = defaultKey doesn't exist! Returning nullptr\n",
      "393458.6ms [  INFO ] [QNN_CPU] QnnContext Free start\n",
      "393470.6ms [  INFO ] [QNN_CPU] QnnContext Free end\n",
      "393469.8ms [WARNING] Profile Logger with name = defaultKey doesn't exist!\n",
      "393471.3ms [  INFO ] [QNN_CPU] QnnBackend Free start\n",
      "393471.4ms [  INFO ] [QNN_CPU] QnnBackend Free end\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-dlc-quantize --input_dlc models/detr_resnet101_fp32.dlc --input_list list.txt  --output_dlc models/detr_resnet101_w8a8.dlc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef45dba-afcd-4843-83b2-cf6be8b6f1f6",
   "metadata": {},
   "source": [
    "- For snpe-dlc-graph-prepare fix value of htp_soc.\n",
    "- Based on the device you will be running set value of <b>--htp_socs. Example sm8650 or sm8550</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c7cb043-00b2-49c5-9368-60845ebb7bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] AISW SDK environment set\n",
      "[INFO] QNN_SDK_ROOT: /opt/qcom/aistack/qairt/2.25.0.240728\n",
      "[INFO] SNPE_ROOT: /opt/qcom/aistack/qairt/2.25.0.240728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] InitializeStderr: DebugLog initialized.\n",
      "[INFO] SNPE HTP Offline Prepare: Attempting to create cache for SM8650\n",
      "[USER_INFO] Target device backend record identifier: HTP_V75_SM8650_8MB\n",
      "[USER_INFO] No cache record in the DLC matches the target device (HTP_V75_SM8650_8MB). Creating a new record\n",
      "[USER_INFO] Checking unsigned PD session\n",
      "[INFO] Attempting to open dynamically linked lib: libHtpPrepare.so\n",
      "[INFO] dlopen libHtpPrepare.so SUCCESS handle 0x562dc14333a0\n",
      "[INFO] Found Interface Provider (v2.18)\n",
      "[USER_WARNING] QnnDsp <W> Initializing HtpProvider\n",
      "[USER_WARNING] QnnDsp <W> HTP arch will be deprecated, please set SoC id instead.\n",
      "[USER_WARNING] QnnDsp <W> Performance Estimates unsupported\n",
      "[USER_INFO] Platform option not set\n",
      "[USER_INFO] Created ctx=0x1 for Graph Id=0 backend=HTP SNPE Id=0x562dc11426f8\n",
      "[USER_INFO] Offline Prepare VTCM size(MB) selected = 8\n",
      "[USER_INFO] Offline Prepare Optimization Level passed = 2\n",
      "[USER_INFO] Backend Mgr ~Dtor called for backend HTP\n",
      "[USER_INFO] Cleaning up Context handle=0x1 for Graph Id=0 backend=HTP SNPE Id=0x562dc11426f8\n",
      "[USER_INFO] Done Cleaning up Context handle=0x1 for Graph Id=0 backend=HTP SNPE Id=0x562dc11426f8\n",
      "[USER_INFO] BackendTerminate triggered\n",
      "[INFO] SNPE HTP Offline Prepare: Successfully created cache for SM8650\n",
      "[INFO] ======== Run Summary ========\n",
      "[INFO]   SM8650 :  Success\n",
      "[USER_INFO] BackendTerminate triggered\n",
      "[INFO] DebugLog shutting down.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source $SNPE_ROOT/bin/envsetup.sh\n",
    "snpe-dlc-graph-prepare --input_dlc models/detr_resnet101_w8a8.dlc --htp_socs=sm8650 --set_output_tensors=5848,5856 --output_dlc=models/detr_resnet101_w8a8_gp.dlc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8561ebf-c06a-4602-9136-84dfde6813d7",
   "metadata": {},
   "source": [
    "**Optional Code blocks**\n",
    "## Creating Bin and Lib Folder On Device\n",
    "\n",
    "<b>- Below blocks are completely optional. \n",
    "- You have the model already prepared.\n",
    "- Run below code blocks only if you want to try out model by pushing it device.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ed7817b-0574-48b6-8c8e-3184f1ca93e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* daemon not running; starting now at tcp:localhost:5037\n",
      "* daemon started successfully\n",
      "adb: device '503bd507' not found\n",
      "adb: device '503bd507' not found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'#source throughput.sh >>dump.txt\\nexport DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\\n$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\"\\n$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\"\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m#source throughput.sh >>dump.txt\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mexport DEVICE_SHELL=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madb -H $DEVICE_HOST -s $DEVICE_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m$DEVICE_SHELL shell \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m && $DEVICE_SHELL shell \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m && $DEVICE_SHELL shell \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmkdir -p /data/local/tmp/snpeexample/dsp/lib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m$DEVICE_SHELL shell \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmkdir -p /data/local/tmp/$ONDEVICE_FOLDER\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2543\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2541\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2542\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2543\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2545\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/script.py:159\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/script.py:336\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'#source throughput.sh >>dump.txt\\nexport DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\\n$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\"\\n$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\"\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#source throughput.sh >>dump.txt\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\" && $DEVICE_SHELL shell \"mkdir -p /data/local/tmp/snpeexample/dsp/lib\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bb8d16-46a7-46fc-835b-0bb53b1a5a66",
   "metadata": {},
   "source": [
    "# Pusing All Bin and Lib Files on to Device\n",
    "* use hexagon-v75 for sm8650\n",
    "* use hexagon-v73 for sm8550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c5228-fb41-4ba7-b1bf-b1b258dadcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/$SNPE_TARGET_STL /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/$SNPE_TARGET_ARCH/*.so /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/lib/hexagon-v75/unsigned/*.so /data/local/tmp/snpeexample/dsp/lib\n",
    "$DEVICE_SHELL push $SNPE_ROOT/bin/$SNPE_TARGET_ARCH/snpe-net-run /data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c7322-6293-45ba-84b0-f48ff22edb67",
   "metadata": {},
   "source": [
    "# Pushing Artifacts onto Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297e7ac-dace-4d31-9fbf-e3829843f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell \"mkdir -p /data/local/tmp/$ONDEVICE_FOLDER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44ca30-4fd9-48a8-a3c5-a735a90defd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL push $RAW_FILE_FOLDER /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $TARGET_INPUT_LIST /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLC32 /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push models/detr_resnet101_w8a8_gp.dlc /data/local/tmp/$ONDEVICE_FOLDER\n",
    "$DEVICE_SHELL push $DLC8 /data/local/tmp/$ONDEVICE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45da446-097d-452e-b9bf-289128391982",
   "metadata": {},
   "source": [
    "# Inferencing 8-bit DLC onto DSP Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d6786-6fd5-4860-8159-e5729d405e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export SNPE_TARGET_ARCH=aarch64-android\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "export ADSP_LIBRARY_PATH=\"/data/local/tmp/snpeexample/dsp/lib;/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp\"\n",
    "export OUTPUT_FOLDER=OUTPUT_8b_DSP\n",
    "export DLC8=detr_resnet101_w8a8_gp.dlc\n",
    "export ONDEVICE_FOLDER=\"detr\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "chmod -R 777 * &&\n",
    "snpe-net-run --container $DLC8 --input_list list.txt  --set_unconsumed_as_output --output_dir=OUTPUT_8b_DSP --use_dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742e8fed-d3af-4938-b3fb-79d7ffe93b79",
   "metadata": {},
   "source": [
    "# Inferencing 32-bit DLC onto CPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4670f413-3cb2-4fd6-8592-ab5b787b47ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL shell\n",
    "export SNPE_TARGET_ARCH=aarch64-android\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/lib\n",
    "export PATH=$PATH:/data/local/tmp/snpeexample/$SNPE_TARGET_ARCH/bin\n",
    "export OUTPUT_FOLDER=OUTPUT_32b_CPU\n",
    "export DLC32=detr_resnet101_fp32.dlc\n",
    "export ONDEVICE_FOLDER=\"detr\"\n",
    "cd /data/local/tmp/$ONDEVICE_FOLDER &&\n",
    "snpe-net-run --container $DLC32 --input_list list.txt  --output_dir=OUTPUT_32b_CPU --set_unconsumed_as_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f272d-4641-4f89-b622-6ab769af29d8",
   "metadata": {},
   "source": [
    "# Pulling output folder generated on different Precision and Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744d5da-3c50-47c6-b354-ff878cc58288",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export DEVICE_SHELL=\"adb -H $DEVICE_HOST -s $DEVICE_ID\"\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_8b_DSP OUTPUT_8b_DSP\n",
    "$DEVICE_SHELL pull /data/local/tmp/$ONDEVICE_FOLDER/OUTPUT_32b_CPU OUTPUT_32b_CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6a41e6-cb53-4a48-ad3f-847432495928",
   "metadata": {},
   "source": [
    "## Post Processing the Inferenced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9b2db-7b39-4a2c-8dda-b3ac55206e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample list of classes\n",
    "CLASSES = [\n",
    "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
    "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
    "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
    "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
    "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
    "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "    'toothbrush'\n",
    "]\n",
    "\n",
    "# colors for visualization\n",
    "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
    "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ba131-f92b-4538-a884-e7d7029283d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "Image_Paths=[]\n",
    "\n",
    "with open('list.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        Image_Paths.append(line.strip().split(\"/\")[-1].split(\".\")[0])\n",
    "\n",
    "\n",
    "count=Image_count=0\n",
    "if os.path.exists(\"output\")==False:\n",
    "    os.mkdir(\"output\")\n",
    "if os.path.exists(\"output/CPU\")==False:\n",
    "    os.mkdir(\"output/CPU\")\n",
    "if os.path.exists(\"output/DSP\")==False:\n",
    "    os.mkdir(\"output/DSP\")\n",
    "for image in Image_Paths:\n",
    "    image_path = 'val2017/'+image+\".jpg\"\n",
    "    im = Image.open(image_path)\n",
    "    file1 = 'OUTPUT_32b_CPU/Result_' + str(count) + '/5867.raw'\n",
    "    file2 = 'OUTPUT_32b_CPU/Result_' + str(count) + '/5860.raw'\n",
    "    file3 = 'OUTPUT_8b_DSP/Result_' + str(count) + '/5867.raw'\n",
    "    file4 = 'OUTPUT_8b_DSP/Result_' + str(count) + '/5860.raw'\n",
    "    a=np.fromfile(file1,np.float32)\n",
    "    a=a.reshape(100,91)\n",
    "    tensor_a = torch.from_numpy(a)\n",
    "    b=np.fromfile(file2,np.float32)\n",
    "    b=b.reshape(1,100,4)\n",
    "    tensor_b = torch.from_numpy(b)\n",
    "\n",
    "    c=np.fromfile(file3,np.float32)\n",
    "    c=c.reshape(100,91)\n",
    "    tensor_c = torch.from_numpy(c)\n",
    "    d=np.fromfile(file4,np.float32)\n",
    "    d=d.reshape(1,100,4)\n",
    "    tensor_d = torch.from_numpy(d)\n",
    "\n",
    "\n",
    "    \n",
    "    probas = tensor_a\n",
    "    keep = probas.max(-1).values > 0.9\n",
    "    bboxes_scaled = rescale_bboxes(tensor_b[0, keep], im.size)\n",
    "    print(\"CPU FP32 Inference Result\")\n",
    "    plot_results(im, probas[keep], bboxes_scaled,Image_count)\n",
    "    Image_count=Image_count+1\n",
    "\n",
    "    probas = tensor_c\n",
    "    keep = probas.max(-1).values > 0.9\n",
    "    bboxes_scaled = rescale_bboxes(tensor_d[0, keep], im.size)\n",
    "    print(\"DSP INT8 Inference Result\")\n",
    "    plot_results(im, probas[keep], bboxes_scaled,Image_count)\n",
    "    Image_count=Image_count+1\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0e3a6-c33d-4320-b61d-e224c85e6438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83386c6f-7c23-4bfb-af4e-8e91d90e129d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
